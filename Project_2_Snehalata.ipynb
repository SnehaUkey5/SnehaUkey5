{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM3NT2dN9lvKMXBfhAa/Mkz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SnehaUkey5/SnehaUkey5/blob/main/Project_2_Snehalata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjStSysUdU6c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df_forestcover = pd.read_csv(\"https://raw.githubusercontent.com/pranavn91/PDF/main/dataset.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_forestcover"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "UQk0uHdfei4h",
        "outputId": "bbb02b1e-30c2-4045-be57-a7f3bcf55c51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Id  Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
              "0          1       2596      51      3                               258   \n",
              "1          2       2590      56      2                               212   \n",
              "2          3       2804     139      9                               268   \n",
              "3          4       2785     155     18                               242   \n",
              "4          5       2595      45      2                               153   \n",
              "...      ...        ...     ...    ...                               ...   \n",
              "15115  15116       2607     243     23                               258   \n",
              "15116  15117       2603     121     19                               633   \n",
              "15117  15118       2492     134     25                               365   \n",
              "15118  15119       2487     167     28                               218   \n",
              "15119  15120       2475     197     34                               319   \n",
              "\n",
              "       Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
              "0                                   0                              510   \n",
              "1                                  -6                              390   \n",
              "2                                  65                             3180   \n",
              "3                                 118                             3090   \n",
              "4                                  -1                              391   \n",
              "...                               ...                              ...   \n",
              "15115                               7                              660   \n",
              "15116                             195                              618   \n",
              "15117                             117                              335   \n",
              "15118                             101                              242   \n",
              "15119                              78                              270   \n",
              "\n",
              "       Hillshade_9am  Hillshade_Noon  Hillshade_3pm  ...  Soil_Type32  \\\n",
              "0                221             232            148  ...            0   \n",
              "1                220             235            151  ...            0   \n",
              "2                234             238            135  ...            0   \n",
              "3                238             238            122  ...            0   \n",
              "4                220             234            150  ...            0   \n",
              "...              ...             ...            ...  ...          ...   \n",
              "15115            170             251            214  ...            0   \n",
              "15116            249             221             91  ...            0   \n",
              "15117            250             220             83  ...            0   \n",
              "15118            229             237            119  ...            0   \n",
              "15119            189             244            164  ...            0   \n",
              "\n",
              "       Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  \\\n",
              "0                0            0            0            0            0   \n",
              "1                0            0            0            0            0   \n",
              "2                0            0            0            0            0   \n",
              "3                0            0            0            0            0   \n",
              "4                0            0            0            0            0   \n",
              "...            ...          ...          ...          ...          ...   \n",
              "15115            0            0            0            0            0   \n",
              "15116            0            0            0            0            0   \n",
              "15117            0            0            0            0            0   \n",
              "15118            0            0            0            0            0   \n",
              "15119            0            0            0            0            0   \n",
              "\n",
              "       Soil_Type38  Soil_Type39  Soil_Type40  Cover_Type  \n",
              "0                0            0            0           5  \n",
              "1                0            0            0           5  \n",
              "2                0            0            0           2  \n",
              "3                0            0            0           2  \n",
              "4                0            0            0           5  \n",
              "...            ...          ...          ...         ...  \n",
              "15115            0            0            0           3  \n",
              "15116            0            0            0           3  \n",
              "15117            0            0            0           3  \n",
              "15118            0            0            0           3  \n",
              "15119            0            0            0           3  \n",
              "\n",
              "[15120 rows x 56 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2da7009e-b7b1-4033-a6e1-961e5d8eda91\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Aspect</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <th>Hillshade_9am</th>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <th>Hillshade_3pm</th>\n",
              "      <th>...</th>\n",
              "      <th>Soil_Type32</th>\n",
              "      <th>Soil_Type33</th>\n",
              "      <th>Soil_Type34</th>\n",
              "      <th>Soil_Type35</th>\n",
              "      <th>Soil_Type36</th>\n",
              "      <th>Soil_Type37</th>\n",
              "      <th>Soil_Type38</th>\n",
              "      <th>Soil_Type39</th>\n",
              "      <th>Soil_Type40</th>\n",
              "      <th>Cover_Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2596</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>510</td>\n",
              "      <td>221</td>\n",
              "      <td>232</td>\n",
              "      <td>148</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2590</td>\n",
              "      <td>56</td>\n",
              "      <td>2</td>\n",
              "      <td>212</td>\n",
              "      <td>-6</td>\n",
              "      <td>390</td>\n",
              "      <td>220</td>\n",
              "      <td>235</td>\n",
              "      <td>151</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2804</td>\n",
              "      <td>139</td>\n",
              "      <td>9</td>\n",
              "      <td>268</td>\n",
              "      <td>65</td>\n",
              "      <td>3180</td>\n",
              "      <td>234</td>\n",
              "      <td>238</td>\n",
              "      <td>135</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2785</td>\n",
              "      <td>155</td>\n",
              "      <td>18</td>\n",
              "      <td>242</td>\n",
              "      <td>118</td>\n",
              "      <td>3090</td>\n",
              "      <td>238</td>\n",
              "      <td>238</td>\n",
              "      <td>122</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2595</td>\n",
              "      <td>45</td>\n",
              "      <td>2</td>\n",
              "      <td>153</td>\n",
              "      <td>-1</td>\n",
              "      <td>391</td>\n",
              "      <td>220</td>\n",
              "      <td>234</td>\n",
              "      <td>150</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15115</th>\n",
              "      <td>15116</td>\n",
              "      <td>2607</td>\n",
              "      <td>243</td>\n",
              "      <td>23</td>\n",
              "      <td>258</td>\n",
              "      <td>7</td>\n",
              "      <td>660</td>\n",
              "      <td>170</td>\n",
              "      <td>251</td>\n",
              "      <td>214</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15116</th>\n",
              "      <td>15117</td>\n",
              "      <td>2603</td>\n",
              "      <td>121</td>\n",
              "      <td>19</td>\n",
              "      <td>633</td>\n",
              "      <td>195</td>\n",
              "      <td>618</td>\n",
              "      <td>249</td>\n",
              "      <td>221</td>\n",
              "      <td>91</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15117</th>\n",
              "      <td>15118</td>\n",
              "      <td>2492</td>\n",
              "      <td>134</td>\n",
              "      <td>25</td>\n",
              "      <td>365</td>\n",
              "      <td>117</td>\n",
              "      <td>335</td>\n",
              "      <td>250</td>\n",
              "      <td>220</td>\n",
              "      <td>83</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15118</th>\n",
              "      <td>15119</td>\n",
              "      <td>2487</td>\n",
              "      <td>167</td>\n",
              "      <td>28</td>\n",
              "      <td>218</td>\n",
              "      <td>101</td>\n",
              "      <td>242</td>\n",
              "      <td>229</td>\n",
              "      <td>237</td>\n",
              "      <td>119</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15119</th>\n",
              "      <td>15120</td>\n",
              "      <td>2475</td>\n",
              "      <td>197</td>\n",
              "      <td>34</td>\n",
              "      <td>319</td>\n",
              "      <td>78</td>\n",
              "      <td>270</td>\n",
              "      <td>189</td>\n",
              "      <td>244</td>\n",
              "      <td>164</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15120 rows × 56 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2da7009e-b7b1-4033-a6e1-961e5d8eda91')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2da7009e-b7b1-4033-a6e1-961e5d8eda91 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2da7009e-b7b1-4033-a6e1-961e5d8eda91');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_forestcover.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9i2jWTjAhkpG",
        "outputId": "6f088f5d-2ed3-49ba-f70b-ce9ae6661ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15120 entries, 0 to 15119\n",
            "Data columns (total 56 columns):\n",
            " #   Column                              Non-Null Count  Dtype\n",
            "---  ------                              --------------  -----\n",
            " 0   Id                                  15120 non-null  int64\n",
            " 1   Elevation                           15120 non-null  int64\n",
            " 2   Aspect                              15120 non-null  int64\n",
            " 3   Slope                               15120 non-null  int64\n",
            " 4   Horizontal_Distance_To_Hydrology    15120 non-null  int64\n",
            " 5   Vertical_Distance_To_Hydrology      15120 non-null  int64\n",
            " 6   Horizontal_Distance_To_Roadways     15120 non-null  int64\n",
            " 7   Hillshade_9am                       15120 non-null  int64\n",
            " 8   Hillshade_Noon                      15120 non-null  int64\n",
            " 9   Hillshade_3pm                       15120 non-null  int64\n",
            " 10  Horizontal_Distance_To_Fire_Points  15120 non-null  int64\n",
            " 11  Wilderness_Area1                    15120 non-null  int64\n",
            " 12  Wilderness_Area2                    15120 non-null  int64\n",
            " 13  Wilderness_Area3                    15120 non-null  int64\n",
            " 14  Wilderness_Area4                    15120 non-null  int64\n",
            " 15  Soil_Type1                          15120 non-null  int64\n",
            " 16  Soil_Type2                          15120 non-null  int64\n",
            " 17  Soil_Type3                          15120 non-null  int64\n",
            " 18  Soil_Type4                          15120 non-null  int64\n",
            " 19  Soil_Type5                          15120 non-null  int64\n",
            " 20  Soil_Type6                          15120 non-null  int64\n",
            " 21  Soil_Type7                          15120 non-null  int64\n",
            " 22  Soil_Type8                          15120 non-null  int64\n",
            " 23  Soil_Type9                          15120 non-null  int64\n",
            " 24  Soil_Type10                         15120 non-null  int64\n",
            " 25  Soil_Type11                         15120 non-null  int64\n",
            " 26  Soil_Type12                         15120 non-null  int64\n",
            " 27  Soil_Type13                         15120 non-null  int64\n",
            " 28  Soil_Type14                         15120 non-null  int64\n",
            " 29  Soil_Type15                         15120 non-null  int64\n",
            " 30  Soil_Type16                         15120 non-null  int64\n",
            " 31  Soil_Type17                         15120 non-null  int64\n",
            " 32  Soil_Type18                         15120 non-null  int64\n",
            " 33  Soil_Type19                         15120 non-null  int64\n",
            " 34  Soil_Type20                         15120 non-null  int64\n",
            " 35  Soil_Type21                         15120 non-null  int64\n",
            " 36  Soil_Type22                         15120 non-null  int64\n",
            " 37  Soil_Type23                         15120 non-null  int64\n",
            " 38  Soil_Type24                         15120 non-null  int64\n",
            " 39  Soil_Type25                         15120 non-null  int64\n",
            " 40  Soil_Type26                         15120 non-null  int64\n",
            " 41  Soil_Type27                         15120 non-null  int64\n",
            " 42  Soil_Type28                         15120 non-null  int64\n",
            " 43  Soil_Type29                         15120 non-null  int64\n",
            " 44  Soil_Type30                         15120 non-null  int64\n",
            " 45  Soil_Type31                         15120 non-null  int64\n",
            " 46  Soil_Type32                         15120 non-null  int64\n",
            " 47  Soil_Type33                         15120 non-null  int64\n",
            " 48  Soil_Type34                         15120 non-null  int64\n",
            " 49  Soil_Type35                         15120 non-null  int64\n",
            " 50  Soil_Type36                         15120 non-null  int64\n",
            " 51  Soil_Type37                         15120 non-null  int64\n",
            " 52  Soil_Type38                         15120 non-null  int64\n",
            " 53  Soil_Type39                         15120 non-null  int64\n",
            " 54  Soil_Type40                         15120 non-null  int64\n",
            " 55  Cover_Type                          15120 non-null  int64\n",
            "dtypes: int64(56)\n",
            "memory usage: 6.5 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_forestcover.isnull().sum()/df_forestcover.shape[0]\n",
        "## Percentage of Null Values in each columndf_forestcover.isna("
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkLPQ1UYjrqp",
        "outputId": "bd4003eb-0bda-4669-b10c-43b84cdd8e09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id                                    0.0\n",
              "Elevation                             0.0\n",
              "Aspect                                0.0\n",
              "Slope                                 0.0\n",
              "Horizontal_Distance_To_Hydrology      0.0\n",
              "Vertical_Distance_To_Hydrology        0.0\n",
              "Horizontal_Distance_To_Roadways       0.0\n",
              "Hillshade_9am                         0.0\n",
              "Hillshade_Noon                        0.0\n",
              "Hillshade_3pm                         0.0\n",
              "Horizontal_Distance_To_Fire_Points    0.0\n",
              "Wilderness_Area1                      0.0\n",
              "Wilderness_Area2                      0.0\n",
              "Wilderness_Area3                      0.0\n",
              "Wilderness_Area4                      0.0\n",
              "Soil_Type1                            0.0\n",
              "Soil_Type2                            0.0\n",
              "Soil_Type3                            0.0\n",
              "Soil_Type4                            0.0\n",
              "Soil_Type5                            0.0\n",
              "Soil_Type6                            0.0\n",
              "Soil_Type7                            0.0\n",
              "Soil_Type8                            0.0\n",
              "Soil_Type9                            0.0\n",
              "Soil_Type10                           0.0\n",
              "Soil_Type11                           0.0\n",
              "Soil_Type12                           0.0\n",
              "Soil_Type13                           0.0\n",
              "Soil_Type14                           0.0\n",
              "Soil_Type15                           0.0\n",
              "Soil_Type16                           0.0\n",
              "Soil_Type17                           0.0\n",
              "Soil_Type18                           0.0\n",
              "Soil_Type19                           0.0\n",
              "Soil_Type20                           0.0\n",
              "Soil_Type21                           0.0\n",
              "Soil_Type22                           0.0\n",
              "Soil_Type23                           0.0\n",
              "Soil_Type24                           0.0\n",
              "Soil_Type25                           0.0\n",
              "Soil_Type26                           0.0\n",
              "Soil_Type27                           0.0\n",
              "Soil_Type28                           0.0\n",
              "Soil_Type29                           0.0\n",
              "Soil_Type30                           0.0\n",
              "Soil_Type31                           0.0\n",
              "Soil_Type32                           0.0\n",
              "Soil_Type33                           0.0\n",
              "Soil_Type34                           0.0\n",
              "Soil_Type35                           0.0\n",
              "Soil_Type36                           0.0\n",
              "Soil_Type37                           0.0\n",
              "Soil_Type38                           0.0\n",
              "Soil_Type39                           0.0\n",
              "Soil_Type40                           0.0\n",
              "Cover_Type                            0.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_forestcover.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "0JDdZSwe6ocY",
        "outputId": "c4b372ce-15c0-4330-f842-1b5a476d4985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Id     Elevation        Aspect         Slope  \\\n",
              "count  15120.00000  15120.000000  15120.000000  15120.000000   \n",
              "mean    7560.50000   2749.322553    156.676653     16.501587   \n",
              "std     4364.91237    417.678187    110.085801      8.453927   \n",
              "min        1.00000   1863.000000      0.000000      0.000000   \n",
              "25%     3780.75000   2376.000000     65.000000     10.000000   \n",
              "50%     7560.50000   2752.000000    126.000000     15.000000   \n",
              "75%    11340.25000   3104.000000    261.000000     22.000000   \n",
              "max    15120.00000   3849.000000    360.000000     52.000000   \n",
              "\n",
              "       Horizontal_Distance_To_Hydrology  Vertical_Distance_To_Hydrology  \\\n",
              "count                      15120.000000                    15120.000000   \n",
              "mean                         227.195701                       51.076521   \n",
              "std                          210.075296                       61.239406   \n",
              "min                            0.000000                     -146.000000   \n",
              "25%                           67.000000                        5.000000   \n",
              "50%                          180.000000                       32.000000   \n",
              "75%                          330.000000                       79.000000   \n",
              "max                         1343.000000                      554.000000   \n",
              "\n",
              "       Horizontal_Distance_To_Roadways  Hillshade_9am  Hillshade_Noon  \\\n",
              "count                     15120.000000   15120.000000    15120.000000   \n",
              "mean                       1714.023214     212.704299      218.965608   \n",
              "std                        1325.066358      30.561287       22.801966   \n",
              "min                           0.000000       0.000000       99.000000   \n",
              "25%                         764.000000     196.000000      207.000000   \n",
              "50%                        1316.000000     220.000000      223.000000   \n",
              "75%                        2270.000000     235.000000      235.000000   \n",
              "max                        6890.000000     254.000000      254.000000   \n",
              "\n",
              "       Hillshade_3pm  ...   Soil_Type32   Soil_Type33   Soil_Type34  \\\n",
              "count   15120.000000  ...  15120.000000  15120.000000  15120.000000   \n",
              "mean      135.091997  ...      0.045635      0.040741      0.001455   \n",
              "std        45.895189  ...      0.208699      0.197696      0.038118   \n",
              "min         0.000000  ...      0.000000      0.000000      0.000000   \n",
              "25%       106.000000  ...      0.000000      0.000000      0.000000   \n",
              "50%       138.000000  ...      0.000000      0.000000      0.000000   \n",
              "75%       167.000000  ...      0.000000      0.000000      0.000000   \n",
              "max       248.000000  ...      1.000000      1.000000      1.000000   \n",
              "\n",
              "        Soil_Type35   Soil_Type36   Soil_Type37   Soil_Type38   Soil_Type39  \\\n",
              "count  15120.000000  15120.000000  15120.000000  15120.000000  15120.000000   \n",
              "mean       0.006746      0.000661      0.002249      0.048148      0.043452   \n",
              "std        0.081859      0.025710      0.047368      0.214086      0.203880   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "        Soil_Type40    Cover_Type  \n",
              "count  15120.000000  15120.000000  \n",
              "mean       0.030357      4.000000  \n",
              "std        0.171574      2.000066  \n",
              "min        0.000000      1.000000  \n",
              "25%        0.000000      2.000000  \n",
              "50%        0.000000      4.000000  \n",
              "75%        0.000000      6.000000  \n",
              "max        1.000000      7.000000  \n",
              "\n",
              "[8 rows x 56 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2238243f-9514-4298-89e4-105787219acd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Aspect</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <th>Hillshade_9am</th>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <th>Hillshade_3pm</th>\n",
              "      <th>...</th>\n",
              "      <th>Soil_Type32</th>\n",
              "      <th>Soil_Type33</th>\n",
              "      <th>Soil_Type34</th>\n",
              "      <th>Soil_Type35</th>\n",
              "      <th>Soil_Type36</th>\n",
              "      <th>Soil_Type37</th>\n",
              "      <th>Soil_Type38</th>\n",
              "      <th>Soil_Type39</th>\n",
              "      <th>Soil_Type40</th>\n",
              "      <th>Cover_Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>15120.00000</td>\n",
              "      <td>15120.000000</td>\n",
              "      <td>15120.000000</td>\n",
              "      <td>15120.000000</td>\n",
              "      <td>15120.000000</td>\n",
              "      <td>15120.000000</td>\n",
              "      <td>15120.000000</td>\n",
              "      <td>15120.000000</td>\n",
              "      <td>15120.000000</td>\n",
              "      <td>15120.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>15120.000000</td>\n",
              "      <td>15120.000000</td>\n",
              "      <td>15120.000000</td>\n",
              "      <td>15120.000000</td>\n",
              "      <td>15120.000000</td>\n",
              "      <td>15120.000000</td>\n",
              "      <td>15120.000000</td>\n",
              "      <td>15120.000000</td>\n",
              "      <td>15120.000000</td>\n",
              "      <td>15120.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7560.50000</td>\n",
              "      <td>2749.322553</td>\n",
              "      <td>156.676653</td>\n",
              "      <td>16.501587</td>\n",
              "      <td>227.195701</td>\n",
              "      <td>51.076521</td>\n",
              "      <td>1714.023214</td>\n",
              "      <td>212.704299</td>\n",
              "      <td>218.965608</td>\n",
              "      <td>135.091997</td>\n",
              "      <td>...</td>\n",
              "      <td>0.045635</td>\n",
              "      <td>0.040741</td>\n",
              "      <td>0.001455</td>\n",
              "      <td>0.006746</td>\n",
              "      <td>0.000661</td>\n",
              "      <td>0.002249</td>\n",
              "      <td>0.048148</td>\n",
              "      <td>0.043452</td>\n",
              "      <td>0.030357</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4364.91237</td>\n",
              "      <td>417.678187</td>\n",
              "      <td>110.085801</td>\n",
              "      <td>8.453927</td>\n",
              "      <td>210.075296</td>\n",
              "      <td>61.239406</td>\n",
              "      <td>1325.066358</td>\n",
              "      <td>30.561287</td>\n",
              "      <td>22.801966</td>\n",
              "      <td>45.895189</td>\n",
              "      <td>...</td>\n",
              "      <td>0.208699</td>\n",
              "      <td>0.197696</td>\n",
              "      <td>0.038118</td>\n",
              "      <td>0.081859</td>\n",
              "      <td>0.025710</td>\n",
              "      <td>0.047368</td>\n",
              "      <td>0.214086</td>\n",
              "      <td>0.203880</td>\n",
              "      <td>0.171574</td>\n",
              "      <td>2.000066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.00000</td>\n",
              "      <td>1863.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-146.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3780.75000</td>\n",
              "      <td>2376.000000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>764.000000</td>\n",
              "      <td>196.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7560.50000</td>\n",
              "      <td>2752.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>180.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>1316.000000</td>\n",
              "      <td>220.000000</td>\n",
              "      <td>223.000000</td>\n",
              "      <td>138.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>11340.25000</td>\n",
              "      <td>3104.000000</td>\n",
              "      <td>261.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>2270.000000</td>\n",
              "      <td>235.000000</td>\n",
              "      <td>235.000000</td>\n",
              "      <td>167.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>15120.00000</td>\n",
              "      <td>3849.000000</td>\n",
              "      <td>360.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>1343.000000</td>\n",
              "      <td>554.000000</td>\n",
              "      <td>6890.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>248.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 56 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2238243f-9514-4298-89e4-105787219acd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2238243f-9514-4298-89e4-105787219acd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2238243f-9514-4298-89e4-105787219acd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_forestcover.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "hJ8cU-UlkJPu",
        "outputId": "e950e429-f5fb-4b3b-ac87-baefeac5a104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
              "0   1       2596      51      3                               258   \n",
              "1   2       2590      56      2                               212   \n",
              "2   3       2804     139      9                               268   \n",
              "3   4       2785     155     18                               242   \n",
              "4   5       2595      45      2                               153   \n",
              "\n",
              "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
              "0                               0                              510   \n",
              "1                              -6                              390   \n",
              "2                              65                             3180   \n",
              "3                             118                             3090   \n",
              "4                              -1                              391   \n",
              "\n",
              "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  ...  Soil_Type32  \\\n",
              "0            221             232            148  ...            0   \n",
              "1            220             235            151  ...            0   \n",
              "2            234             238            135  ...            0   \n",
              "3            238             238            122  ...            0   \n",
              "4            220             234            150  ...            0   \n",
              "\n",
              "   Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  \\\n",
              "0            0            0            0            0            0   \n",
              "1            0            0            0            0            0   \n",
              "2            0            0            0            0            0   \n",
              "3            0            0            0            0            0   \n",
              "4            0            0            0            0            0   \n",
              "\n",
              "   Soil_Type38  Soil_Type39  Soil_Type40  Cover_Type  \n",
              "0            0            0            0           5  \n",
              "1            0            0            0           5  \n",
              "2            0            0            0           2  \n",
              "3            0            0            0           2  \n",
              "4            0            0            0           5  \n",
              "\n",
              "[5 rows x 56 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a779f1e2-e453-4d1a-a16f-90c119a91a59\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Aspect</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <th>Hillshade_9am</th>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <th>Hillshade_3pm</th>\n",
              "      <th>...</th>\n",
              "      <th>Soil_Type32</th>\n",
              "      <th>Soil_Type33</th>\n",
              "      <th>Soil_Type34</th>\n",
              "      <th>Soil_Type35</th>\n",
              "      <th>Soil_Type36</th>\n",
              "      <th>Soil_Type37</th>\n",
              "      <th>Soil_Type38</th>\n",
              "      <th>Soil_Type39</th>\n",
              "      <th>Soil_Type40</th>\n",
              "      <th>Cover_Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2596</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>510</td>\n",
              "      <td>221</td>\n",
              "      <td>232</td>\n",
              "      <td>148</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2590</td>\n",
              "      <td>56</td>\n",
              "      <td>2</td>\n",
              "      <td>212</td>\n",
              "      <td>-6</td>\n",
              "      <td>390</td>\n",
              "      <td>220</td>\n",
              "      <td>235</td>\n",
              "      <td>151</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2804</td>\n",
              "      <td>139</td>\n",
              "      <td>9</td>\n",
              "      <td>268</td>\n",
              "      <td>65</td>\n",
              "      <td>3180</td>\n",
              "      <td>234</td>\n",
              "      <td>238</td>\n",
              "      <td>135</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2785</td>\n",
              "      <td>155</td>\n",
              "      <td>18</td>\n",
              "      <td>242</td>\n",
              "      <td>118</td>\n",
              "      <td>3090</td>\n",
              "      <td>238</td>\n",
              "      <td>238</td>\n",
              "      <td>122</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2595</td>\n",
              "      <td>45</td>\n",
              "      <td>2</td>\n",
              "      <td>153</td>\n",
              "      <td>-1</td>\n",
              "      <td>391</td>\n",
              "      <td>220</td>\n",
              "      <td>234</td>\n",
              "      <td>150</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 56 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a779f1e2-e453-4d1a-a16f-90c119a91a59')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a779f1e2-e453-4d1a-a16f-90c119a91a59 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a779f1e2-e453-4d1a-a16f-90c119a91a59');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_forestcover.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "9YXG9PEWkScr",
        "outputId": "8e78e58d-a92e-4069-c6a4-82214ed7896f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Id  Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
              "15115  15116       2607     243     23                               258   \n",
              "15116  15117       2603     121     19                               633   \n",
              "15117  15118       2492     134     25                               365   \n",
              "15118  15119       2487     167     28                               218   \n",
              "15119  15120       2475     197     34                               319   \n",
              "\n",
              "       Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
              "15115                               7                              660   \n",
              "15116                             195                              618   \n",
              "15117                             117                              335   \n",
              "15118                             101                              242   \n",
              "15119                              78                              270   \n",
              "\n",
              "       Hillshade_9am  Hillshade_Noon  Hillshade_3pm  ...  Soil_Type32  \\\n",
              "15115            170             251            214  ...            0   \n",
              "15116            249             221             91  ...            0   \n",
              "15117            250             220             83  ...            0   \n",
              "15118            229             237            119  ...            0   \n",
              "15119            189             244            164  ...            0   \n",
              "\n",
              "       Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  \\\n",
              "15115            0            0            0            0            0   \n",
              "15116            0            0            0            0            0   \n",
              "15117            0            0            0            0            0   \n",
              "15118            0            0            0            0            0   \n",
              "15119            0            0            0            0            0   \n",
              "\n",
              "       Soil_Type38  Soil_Type39  Soil_Type40  Cover_Type  \n",
              "15115            0            0            0           3  \n",
              "15116            0            0            0           3  \n",
              "15117            0            0            0           3  \n",
              "15118            0            0            0           3  \n",
              "15119            0            0            0           3  \n",
              "\n",
              "[5 rows x 56 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0818abfd-6553-44c6-83ae-1d2ac54af8e2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Aspect</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <th>Hillshade_9am</th>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <th>Hillshade_3pm</th>\n",
              "      <th>...</th>\n",
              "      <th>Soil_Type32</th>\n",
              "      <th>Soil_Type33</th>\n",
              "      <th>Soil_Type34</th>\n",
              "      <th>Soil_Type35</th>\n",
              "      <th>Soil_Type36</th>\n",
              "      <th>Soil_Type37</th>\n",
              "      <th>Soil_Type38</th>\n",
              "      <th>Soil_Type39</th>\n",
              "      <th>Soil_Type40</th>\n",
              "      <th>Cover_Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15115</th>\n",
              "      <td>15116</td>\n",
              "      <td>2607</td>\n",
              "      <td>243</td>\n",
              "      <td>23</td>\n",
              "      <td>258</td>\n",
              "      <td>7</td>\n",
              "      <td>660</td>\n",
              "      <td>170</td>\n",
              "      <td>251</td>\n",
              "      <td>214</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15116</th>\n",
              "      <td>15117</td>\n",
              "      <td>2603</td>\n",
              "      <td>121</td>\n",
              "      <td>19</td>\n",
              "      <td>633</td>\n",
              "      <td>195</td>\n",
              "      <td>618</td>\n",
              "      <td>249</td>\n",
              "      <td>221</td>\n",
              "      <td>91</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15117</th>\n",
              "      <td>15118</td>\n",
              "      <td>2492</td>\n",
              "      <td>134</td>\n",
              "      <td>25</td>\n",
              "      <td>365</td>\n",
              "      <td>117</td>\n",
              "      <td>335</td>\n",
              "      <td>250</td>\n",
              "      <td>220</td>\n",
              "      <td>83</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15118</th>\n",
              "      <td>15119</td>\n",
              "      <td>2487</td>\n",
              "      <td>167</td>\n",
              "      <td>28</td>\n",
              "      <td>218</td>\n",
              "      <td>101</td>\n",
              "      <td>242</td>\n",
              "      <td>229</td>\n",
              "      <td>237</td>\n",
              "      <td>119</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15119</th>\n",
              "      <td>15120</td>\n",
              "      <td>2475</td>\n",
              "      <td>197</td>\n",
              "      <td>34</td>\n",
              "      <td>319</td>\n",
              "      <td>78</td>\n",
              "      <td>270</td>\n",
              "      <td>189</td>\n",
              "      <td>244</td>\n",
              "      <td>164</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 56 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0818abfd-6553-44c6-83ae-1d2ac54af8e2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0818abfd-6553-44c6-83ae-1d2ac54af8e2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0818abfd-6553-44c6-83ae-1d2ac54af8e2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(df_forestcover.corr(), annot=True, cmap=\"YlGnBu\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "Y8x5TUuJlpbS",
        "outputId": "fde68eee-ca85-4723-85da-fb54ef2742f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_forestcover.plot.hexbin(x='Slope', y='Cover_Type', gridsize=10,cmap=\"YlGnBu\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "2-u5fKabIMaO",
        "outputId": "da9d600f-5bed-42f7-b2ca-37b44c2a3435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_forestcover.corr('spearman')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hrrdCFMrzgpI",
        "outputId": "8a2d97a0-abdb-467b-a87f-0a3c740a2587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Id  Elevation    Aspect     Slope  \\\n",
              "Id                                  1.000000   0.180974  0.023739 -0.004949   \n",
              "Elevation                           0.180974   1.000000 -0.008893 -0.307724   \n",
              "Aspect                              0.023739  -0.008893  1.000000  0.046002   \n",
              "Slope                              -0.004949  -0.307724  0.046002  1.000000   \n",
              "Horizontal_Distance_To_Hydrology    0.071122   0.382550  0.034378  0.025893   \n",
              "Vertical_Distance_To_Hydrology      0.036881   0.092769  0.071070  0.333128   \n",
              "Horizontal_Distance_To_Roadways     0.053789   0.596820  0.072618 -0.275328   \n",
              "Hillshade_9am                      -0.016026   0.024188 -0.419927 -0.010455   \n",
              "Hillshade_Noon                      0.060624   0.203171  0.402474 -0.536903   \n",
              "Hillshade_3pm                       0.035596   0.086092  0.627344 -0.283618   \n",
              "Horizontal_Distance_To_Fire_Points -0.004136   0.508872 -0.059489 -0.235185   \n",
              "Wilderness_Area1                   -0.339861   0.338674 -0.123979 -0.160766   \n",
              "Wilderness_Area2                    0.158484   0.254770  0.022381 -0.063539   \n",
              "Wilderness_Area3                    0.384219   0.358016  0.037047 -0.097961   \n",
              "Wilderness_Area4                   -0.158451  -0.792831  0.066010  0.277289   \n",
              "Soil_Type1                         -0.058451  -0.217966 -0.014050  0.101050   \n",
              "Soil_Type2                          0.045545  -0.149352 -0.006420 -0.078279   \n",
              "Soil_Type3                         -0.045757  -0.316436 -0.014578  0.246474   \n",
              "Soil_Type4                          0.118214  -0.125560  0.054990  0.099734   \n",
              "Soil_Type5                         -0.041713  -0.138551 -0.009963  0.070435   \n",
              "Soil_Type6                         -0.046017  -0.184140 -0.005831 -0.044602   \n",
              "Soil_Type7                               NaN        NaN       NaN       NaN   \n",
              "Soil_Type8                         -0.013159   0.003649  0.003878 -0.013495   \n",
              "Soil_Type9                         -0.014219  -0.010578 -0.021238 -0.022186   \n",
              "Soil_Type10                         0.032292  -0.360877  0.052599  0.261403   \n",
              "Soil_Type11                         0.063372  -0.037197 -0.040827 -0.113955   \n",
              "Soil_Type12                        -0.129930   0.019909 -0.040888 -0.124104   \n",
              "Soil_Type13                         0.015145   0.046983  0.041842  0.129632   \n",
              "Soil_Type14                        -0.016034  -0.143683 -0.006563 -0.054104   \n",
              "Soil_Type15                              NaN        NaN       NaN       NaN   \n",
              "Soil_Type16                        -0.003794  -0.066457  0.024807 -0.067588   \n",
              "Soil_Type17                        -0.002940  -0.203990  0.023699 -0.130424   \n",
              "Soil_Type18                        -0.070252  -0.034106 -0.042153 -0.077490   \n",
              "Soil_Type19                        -0.029707   0.032369  0.004654 -0.050617   \n",
              "Soil_Type20                        -0.069537   0.010290 -0.030183 -0.071671   \n",
              "Soil_Type21                         0.014734   0.032750  0.018012 -0.037301   \n",
              "Soil_Type22                         0.035739   0.146604  0.018103 -0.076289   \n",
              "Soil_Type23                        -0.017422   0.164661  0.034793 -0.196010   \n",
              "Soil_Type24                         0.034019   0.099750 -0.010875  0.032107   \n",
              "Soil_Type25                         0.005675   0.010422 -0.000050  0.010968   \n",
              "Soil_Type26                         0.031176   0.024609 -0.000816 -0.030860   \n",
              "Soil_Type27                         0.024141   0.039867  0.021210  0.016634   \n",
              "Soil_Type28                        -0.005104  -0.000803  0.023306  0.030519   \n",
              "Soil_Type29                        -0.231780   0.173524 -0.066358 -0.078882   \n",
              "Soil_Type30                        -0.157515   0.050948 -0.064256  0.116337   \n",
              "Soil_Type31                         0.025826   0.094913 -0.001893 -0.077402   \n",
              "Soil_Type32                         0.068048   0.177010  0.000030 -0.152895   \n",
              "Soil_Type33                         0.066887   0.127712  0.018728  0.085263   \n",
              "Soil_Type34                         0.022520   0.023214  0.016168 -0.032372   \n",
              "Soil_Type35                         0.057480   0.119577  0.002710 -0.050070   \n",
              "Soil_Type36                         0.009110   0.040554  0.010398 -0.001527   \n",
              "Soil_Type37                         0.016040   0.073433 -0.051523  0.004761   \n",
              "Soil_Type38                         0.086932   0.321949  0.043918 -0.154715   \n",
              "Soil_Type39                         0.083376   0.294134 -0.032364  0.056108   \n",
              "Soil_Type40                         0.122475   0.281407 -0.006624 -0.039752   \n",
              "Cover_Type                          0.108363   0.004112  0.003701  0.095533   \n",
              "\n",
              "                                    Horizontal_Distance_To_Hydrology  \\\n",
              "Id                                                          0.071122   \n",
              "Elevation                                                   0.382550   \n",
              "Aspect                                                      0.034378   \n",
              "Slope                                                       0.025893   \n",
              "Horizontal_Distance_To_Hydrology                            1.000000   \n",
              "Vertical_Distance_To_Hydrology                              0.695442   \n",
              "Horizontal_Distance_To_Roadways                             0.139846   \n",
              "Hillshade_9am                                              -0.044380   \n",
              "Hillshade_Noon                                              0.031262   \n",
              "Hillshade_3pm                                               0.049454   \n",
              "Horizontal_Distance_To_Fire_Points                          0.185253   \n",
              "Wilderness_Area1                                            0.030364   \n",
              "Wilderness_Area2                                            0.091548   \n",
              "Wilderness_Area3                                            0.165121   \n",
              "Wilderness_Area4                                           -0.239695   \n",
              "Soil_Type1                                                 -0.097272   \n",
              "Soil_Type2                                                  0.056110   \n",
              "Soil_Type3                                                 -0.071691   \n",
              "Soil_Type4                                                 -0.054540   \n",
              "Soil_Type5                                                 -0.021528   \n",
              "Soil_Type6                                                  0.051428   \n",
              "Soil_Type7                                                       NaN   \n",
              "Soil_Type8                                                  0.006004   \n",
              "Soil_Type9                                                 -0.001103   \n",
              "Soil_Type10                                                -0.081998   \n",
              "Soil_Type11                                                 0.035057   \n",
              "Soil_Type12                                                 0.054548   \n",
              "Soil_Type13                                                 0.036216   \n",
              "Soil_Type14                                                -0.157802   \n",
              "Soil_Type15                                                      NaN   \n",
              "Soil_Type16                                                -0.116091   \n",
              "Soil_Type17                                                -0.233485   \n",
              "Soil_Type18                                                -0.009517   \n",
              "Soil_Type19                                                -0.043054   \n",
              "Soil_Type20                                                -0.089375   \n",
              "Soil_Type21                                                -0.031302   \n",
              "Soil_Type22                                                 0.008889   \n",
              "Soil_Type23                                                -0.109752   \n",
              "Soil_Type24                                                 0.042611   \n",
              "Soil_Type25                                                -0.004300   \n",
              "Soil_Type26                                                 0.029898   \n",
              "Soil_Type27                                                 0.029541   \n",
              "Soil_Type28                                                 0.013313   \n",
              "Soil_Type29                                                 0.066650   \n",
              "Soil_Type30                                                -0.003192   \n",
              "Soil_Type31                                                 0.050385   \n",
              "Soil_Type32                                                 0.152044   \n",
              "Soil_Type33                                                 0.070031   \n",
              "Soil_Type34                                                 0.045031   \n",
              "Soil_Type35                                                -0.033122   \n",
              "Soil_Type36                                                 0.042023   \n",
              "Soil_Type37                                                -0.017976   \n",
              "Soil_Type38                                                 0.081793   \n",
              "Soil_Type39                                                 0.076257   \n",
              "Soil_Type40                                                 0.183069   \n",
              "Cover_Type                                                 -0.050755   \n",
              "\n",
              "                                    Vertical_Distance_To_Hydrology  \\\n",
              "Id                                                        0.036881   \n",
              "Elevation                                                 0.092769   \n",
              "Aspect                                                    0.071070   \n",
              "Slope                                                     0.333128   \n",
              "Horizontal_Distance_To_Hydrology                          0.695442   \n",
              "Vertical_Distance_To_Hydrology                            1.000000   \n",
              "Horizontal_Distance_To_Roadways                          -0.025484   \n",
              "Hillshade_9am                                            -0.054841   \n",
              "Hillshade_Noon                                           -0.148982   \n",
              "Hillshade_3pm                                            -0.029066   \n",
              "Horizontal_Distance_To_Fire_Points                        0.009458   \n",
              "Wilderness_Area1                                         -0.103723   \n",
              "Wilderness_Area2                                          0.011631   \n",
              "Wilderness_Area3                                          0.060976   \n",
              "Wilderness_Area4                                          0.025950   \n",
              "Soil_Type1                                               -0.040180   \n",
              "Soil_Type2                                                0.021591   \n",
              "Soil_Type3                                                0.095937   \n",
              "Soil_Type4                                               -0.012786   \n",
              "Soil_Type5                                                0.017048   \n",
              "Soil_Type6                                                0.095840   \n",
              "Soil_Type7                                                     NaN   \n",
              "Soil_Type8                                               -0.012317   \n",
              "Soil_Type9                                               -0.016549   \n",
              "Soil_Type10                                               0.055891   \n",
              "Soil_Type11                                              -0.013766   \n",
              "Soil_Type12                                              -0.016643   \n",
              "Soil_Type13                                               0.092643   \n",
              "Soil_Type14                                              -0.127907   \n",
              "Soil_Type15                                                    NaN   \n",
              "Soil_Type16                                              -0.099319   \n",
              "Soil_Type17                                              -0.216830   \n",
              "Soil_Type18                                              -0.043664   \n",
              "Soil_Type19                                              -0.053157   \n",
              "Soil_Type20                                              -0.092467   \n",
              "Soil_Type21                                              -0.025833   \n",
              "Soil_Type22                                              -0.064589   \n",
              "Soil_Type23                                              -0.170808   \n",
              "Soil_Type24                                               0.025812   \n",
              "Soil_Type25                                              -0.013878   \n",
              "Soil_Type26                                              -0.006292   \n",
              "Soil_Type27                                               0.023702   \n",
              "Soil_Type28                                               0.010826   \n",
              "Soil_Type29                                              -0.026890   \n",
              "Soil_Type30                                               0.011829   \n",
              "Soil_Type31                                               0.010568   \n",
              "Soil_Type32                                               0.041557   \n",
              "Soil_Type33                                               0.080899   \n",
              "Soil_Type34                                               0.022227   \n",
              "Soil_Type35                                              -0.046257   \n",
              "Soil_Type36                                               0.025059   \n",
              "Soil_Type37                                              -0.028168   \n",
              "Soil_Type38                                              -0.018610   \n",
              "Soil_Type39                                               0.061113   \n",
              "Soil_Type40                                               0.153158   \n",
              "Cover_Type                                                0.049991   \n",
              "\n",
              "                                    Horizontal_Distance_To_Roadways  \\\n",
              "Id                                                         0.053789   \n",
              "Elevation                                                  0.596820   \n",
              "Aspect                                                     0.072618   \n",
              "Slope                                                     -0.275328   \n",
              "Horizontal_Distance_To_Hydrology                           0.139846   \n",
              "Vertical_Distance_To_Hydrology                            -0.025484   \n",
              "Horizontal_Distance_To_Roadways                            1.000000   \n",
              "Hillshade_9am                                             -0.067327   \n",
              "Hillshade_Noon                                             0.251642   \n",
              "Hillshade_3pm                                              0.182770   \n",
              "Horizontal_Distance_To_Fire_Points                         0.421900   \n",
              "Wilderness_Area1                                           0.248010   \n",
              "Wilderness_Area2                                          -0.062155   \n",
              "Wilderness_Area3                                           0.259070   \n",
              "Wilderness_Area4                                          -0.481132   \n",
              "Soil_Type1                                                -0.150565   \n",
              "Soil_Type2                                                -0.074768   \n",
              "Soil_Type3                                                -0.165107   \n",
              "Soil_Type4                                                -0.076162   \n",
              "Soil_Type5                                                -0.118069   \n",
              "Soil_Type6                                                -0.144926   \n",
              "Soil_Type7                                                      NaN   \n",
              "Soil_Type8                                                 0.012802   \n",
              "Soil_Type9                                                -0.022715   \n",
              "Soil_Type10                                               -0.212776   \n",
              "Soil_Type11                                               -0.077586   \n",
              "Soil_Type12                                                0.082255   \n",
              "Soil_Type13                                                0.055979   \n",
              "Soil_Type14                                               -0.079801   \n",
              "Soil_Type15                                                     NaN   \n",
              "Soil_Type16                                               -0.019780   \n",
              "Soil_Type17                                               -0.051390   \n",
              "Soil_Type18                                               -0.045777   \n",
              "Soil_Type19                                                0.050708   \n",
              "Soil_Type20                                                0.043680   \n",
              "Soil_Type21                                                0.004895   \n",
              "Soil_Type22                                                0.070697   \n",
              "Soil_Type23                                                0.131757   \n",
              "Soil_Type24                                                0.026721   \n",
              "Soil_Type25                                               -0.008552   \n",
              "Soil_Type26                                                0.049425   \n",
              "Soil_Type27                                                0.028277   \n",
              "Soil_Type28                                               -0.008690   \n",
              "Soil_Type29                                                0.176204   \n",
              "Soil_Type30                                               -0.129635   \n",
              "Soil_Type31                                                0.067611   \n",
              "Soil_Type32                                                0.073202   \n",
              "Soil_Type33                                                0.074930   \n",
              "Soil_Type34                                                0.028308   \n",
              "Soil_Type35                                                0.081723   \n",
              "Soil_Type36                                                0.032179   \n",
              "Soil_Type37                                                0.062208   \n",
              "Soil_Type38                                                0.205165   \n",
              "Soil_Type39                                                0.161078   \n",
              "Soil_Type40                                                0.142089   \n",
              "Cover_Type                                                -0.064658   \n",
              "\n",
              "                                    Hillshade_9am  Hillshade_Noon  \\\n",
              "Id                                      -0.016026        0.060624   \n",
              "Elevation                                0.024188        0.203171   \n",
              "Aspect                                  -0.419927        0.402474   \n",
              "Slope                                   -0.010455       -0.536903   \n",
              "Horizontal_Distance_To_Hydrology        -0.044380        0.031262   \n",
              "Vertical_Distance_To_Hydrology          -0.054841       -0.148982   \n",
              "Horizontal_Distance_To_Roadways         -0.067327        0.251642   \n",
              "Hillshade_9am                            1.000000       -0.135688   \n",
              "Hillshade_Noon                          -0.135688        1.000000   \n",
              "Hillshade_3pm                           -0.835658        0.582819   \n",
              "Horizontal_Distance_To_Fire_Points       0.038279        0.103556   \n",
              "Wilderness_Area1                         0.161057       -0.011370   \n",
              "Wilderness_Area2                        -0.019120        0.029332   \n",
              "Wilderness_Area3                        -0.073365        0.183425   \n",
              "Wilderness_Area4                        -0.062647       -0.196743   \n",
              "Soil_Type1                               0.042056       -0.017270   \n",
              "Soil_Type2                               0.049014        0.088938   \n",
              "Soil_Type3                               0.301526       -0.105215   \n",
              "Soil_Type4                               0.040495        0.166102   \n",
              "Soil_Type5                              -0.040538       -0.078700   \n",
              "Soil_Type6                               0.014107        0.019206   \n",
              "Soil_Type7                                    NaN             NaN   \n",
              "Soil_Type8                               0.000108        0.009383   \n",
              "Soil_Type9                               0.002238        0.001449   \n",
              "Soil_Type10                             -0.331203       -0.271683   \n",
              "Soil_Type11                              0.006689        0.024886   \n",
              "Soil_Type12                              0.033838        0.050942   \n",
              "Soil_Type13                              0.046697        0.002466   \n",
              "Soil_Type14                             -0.018760        0.000482   \n",
              "Soil_Type15                                   NaN             NaN   \n",
              "Soil_Type16                             -0.017119        0.046196   \n",
              "Soil_Type17                             -0.047580        0.086260   \n",
              "Soil_Type18                              0.019033        0.023946   \n",
              "Soil_Type19                             -0.014371        0.038726   \n",
              "Soil_Type20                             -0.006872        0.011346   \n",
              "Soil_Type21                             -0.015088        0.031807   \n",
              "Soil_Type22                             -0.018078        0.053536   \n",
              "Soil_Type23                             -0.043857        0.133959   \n",
              "Soil_Type24                             -0.057282       -0.072282   \n",
              "Soil_Type25                              0.013547       -0.006672   \n",
              "Soil_Type26                              0.018732        0.047315   \n",
              "Soil_Type27                             -0.011914        0.028646   \n",
              "Soil_Type28                             -0.039088        0.008666   \n",
              "Soil_Type29                              0.043233       -0.010079   \n",
              "Soil_Type30                              0.196192       -0.113194   \n",
              "Soil_Type31                             -0.042192        0.038758   \n",
              "Soil_Type32                             -0.013400        0.096333   \n",
              "Soil_Type33                             -0.034492       -0.014229   \n",
              "Soil_Type34                             -0.003051        0.038619   \n",
              "Soil_Type35                              0.027107        0.035543   \n",
              "Soil_Type36                              0.013432        0.034402   \n",
              "Soil_Type37                              0.006541       -0.037890   \n",
              "Soil_Type38                             -0.016841        0.103441   \n",
              "Soil_Type39                              0.034610       -0.072378   \n",
              "Soil_Type40                             -0.038669       -0.026886   \n",
              "Cover_Type                              -0.003138       -0.099153   \n",
              "\n",
              "                                    Hillshade_3pm  ...  Soil_Type32  \\\n",
              "Id                                       0.035596  ...     0.068048   \n",
              "Elevation                                0.086092  ...     0.177010   \n",
              "Aspect                                   0.627344  ...     0.000030   \n",
              "Slope                                   -0.283618  ...    -0.152895   \n",
              "Horizontal_Distance_To_Hydrology         0.049454  ...     0.152044   \n",
              "Vertical_Distance_To_Hydrology          -0.029066  ...     0.041557   \n",
              "Horizontal_Distance_To_Roadways          0.182770  ...     0.073202   \n",
              "Hillshade_9am                           -0.835658  ...    -0.013400   \n",
              "Hillshade_Noon                           0.582819  ...     0.096333   \n",
              "Hillshade_3pm                            1.000000  ...     0.059921   \n",
              "Horizontal_Distance_To_Fire_Points       0.029902  ...     0.056947   \n",
              "Wilderness_Area1                        -0.123404  ...    -0.122174   \n",
              "Wilderness_Area2                         0.037945  ...     0.023467   \n",
              "Wilderness_Area3                         0.127071  ...     0.233901   \n",
              "Wilderness_Area4                        -0.036673  ...    -0.146294   \n",
              "Soil_Type1                              -0.058902  ...    -0.033907   \n",
              "Soil_Type2                               0.005238  ...    -0.045331   \n",
              "Soil_Type3                              -0.264907  ...    -0.057000   \n",
              "Soil_Type4                               0.016398  ...    -0.053136   \n",
              "Soil_Type5                              -0.016228  ...    -0.022969   \n",
              "Soil_Type6                               0.001240  ...    -0.046346   \n",
              "Soil_Type7                                    NaN  ...          NaN   \n",
              "Soil_Type8                               0.004602  ...    -0.001778   \n",
              "Soil_Type9                              -0.002371  ...    -0.005625   \n",
              "Soil_Type10                              0.118730  ...    -0.088838   \n",
              "Soil_Type11                              0.011609  ...    -0.036324   \n",
              "Soil_Type12                              0.001247  ...    -0.026997   \n",
              "Soil_Type13                             -0.029227  ...    -0.039424   \n",
              "Soil_Type14                              0.018319  ...    -0.023249   \n",
              "Soil_Type15                                   NaN  ...          NaN   \n",
              "Soil_Type16                              0.039931  ...    -0.019059   \n",
              "Soil_Type17                              0.082756  ...    -0.044912   \n",
              "Soil_Type18                             -0.001296  ...    -0.013802   \n",
              "Soil_Type19                              0.030854  ...    -0.012080   \n",
              "Soil_Type20                              0.009797  ...    -0.021063   \n",
              "Soil_Type21                              0.028361  ...    -0.007117   \n",
              "Soil_Type22                              0.041999  ...    -0.033415   \n",
              "Soil_Type23                              0.103708  ...    -0.050202   \n",
              "Soil_Type24                              0.009329  ...    -0.028754   \n",
              "Soil_Type25                             -0.012023  ...    -0.001778   \n",
              "Soil_Type26                              0.007193  ...    -0.013091   \n",
              "Soil_Type27                              0.021857  ...    -0.006891   \n",
              "Soil_Type28                              0.040561  ...    -0.005337   \n",
              "Soil_Type29                             -0.040977  ...    -0.066813   \n",
              "Soil_Type30                             -0.203593  ...    -0.049074   \n",
              "Soil_Type31                              0.052327  ...    -0.032765   \n",
              "Soil_Type32                              0.059921  ...     1.000000   \n",
              "Soil_Type33                              0.016483  ...    -0.045065   \n",
              "Soil_Type34                              0.021390  ...    -0.008347   \n",
              "Soil_Type35                             -0.002470  ...    -0.018021   \n",
              "Soil_Type36                              0.004303  ...    -0.005625   \n",
              "Soil_Type37                             -0.030732  ...    -0.010381   \n",
              "Soil_Type38                              0.071472  ...    -0.049181   \n",
              "Soil_Type39                             -0.062608  ...    -0.046606   \n",
              "Soil_Type40                              0.025373  ...    -0.038692   \n",
              "Cover_Type                              -0.044096  ...    -0.132312   \n",
              "\n",
              "                                    Soil_Type33  Soil_Type34  Soil_Type35  \\\n",
              "Id                                     0.066887     0.022520     0.057480   \n",
              "Elevation                              0.127712     0.023214     0.119577   \n",
              "Aspect                                 0.018728     0.016168     0.002710   \n",
              "Slope                                  0.085263    -0.032372    -0.050070   \n",
              "Horizontal_Distance_To_Hydrology       0.070031     0.045031    -0.033122   \n",
              "Vertical_Distance_To_Hydrology         0.080899     0.022227    -0.046257   \n",
              "Horizontal_Distance_To_Roadways        0.074930     0.028308     0.081723   \n",
              "Hillshade_9am                         -0.034492    -0.003051     0.027107   \n",
              "Hillshade_Noon                        -0.014229     0.038619     0.035543   \n",
              "Hillshade_3pm                          0.016483     0.021390    -0.002470   \n",
              "Horizontal_Distance_To_Fire_Points     0.071669    -0.003391    -0.004230   \n",
              "Wilderness_Area1                      -0.115142    -0.021327     0.007086   \n",
              "Wilderness_Area2                       0.025601    -0.007052     0.011912   \n",
              "Wilderness_Area3                       0.219177     0.044867     0.041204   \n",
              "Wilderness_Area4                      -0.137874    -0.025538    -0.055135   \n",
              "Soil_Type1                            -0.031955    -0.005919    -0.012779   \n",
              "Soil_Type2                            -0.042722    -0.007913    -0.017084   \n",
              "Soil_Type3                            -0.053720    -0.009950    -0.021482   \n",
              "Soil_Type4                            -0.050077    -0.009276    -0.020026   \n",
              "Soil_Type5                            -0.021647    -0.004010    -0.008657   \n",
              "Soil_Type6                            -0.043679    -0.008090    -0.017467   \n",
              "Soil_Type7                                  NaN          NaN          NaN   \n",
              "Soil_Type8                            -0.001676    -0.000310    -0.000670   \n",
              "Soil_Type9                            -0.005302    -0.000982    -0.002120   \n",
              "Soil_Type10                           -0.083724    -0.015508    -0.033481   \n",
              "Soil_Type11                           -0.034233    -0.006341    -0.013690   \n",
              "Soil_Type12                           -0.025443    -0.004713    -0.010175   \n",
              "Soil_Type13                           -0.037155    -0.006882    -0.014858   \n",
              "Soil_Type14                           -0.021911    -0.004058    -0.008762   \n",
              "Soil_Type15                                 NaN          NaN          NaN   \n",
              "Soil_Type16                           -0.017962    -0.003327    -0.007183   \n",
              "Soil_Type17                           -0.042327    -0.007840    -0.016926   \n",
              "Soil_Type18                           -0.013008    -0.002409    -0.005202   \n",
              "Soil_Type19                           -0.011384    -0.002109    -0.004553   \n",
              "Soil_Type20                           -0.019851    -0.003677    -0.007938   \n",
              "Soil_Type21                           -0.006707    -0.001242    -0.002682   \n",
              "Soil_Type22                           -0.031491    -0.005833    -0.012593   \n",
              "Soil_Type23                           -0.047312    -0.008763    -0.018920   \n",
              "Soil_Type24                           -0.027099    -0.005020    -0.010837   \n",
              "Soil_Type25                           -0.001676    -0.000310    -0.000670   \n",
              "Soil_Type26                           -0.012338    -0.002285    -0.004934   \n",
              "Soil_Type27                           -0.006494    -0.001203    -0.002597   \n",
              "Soil_Type28                           -0.005029    -0.000932    -0.002011   \n",
              "Soil_Type29                           -0.062967    -0.011663    -0.025180   \n",
              "Soil_Type30                           -0.046250    -0.008567    -0.018495   \n",
              "Soil_Type31                           -0.030879    -0.005720    -0.012348   \n",
              "Soil_Type32                           -0.045065    -0.008347    -0.018021   \n",
              "Soil_Type33                            1.000000    -0.007867    -0.016984   \n",
              "Soil_Type34                           -0.007867     1.000000    -0.003146   \n",
              "Soil_Type35                           -0.016984    -0.003146     1.000000   \n",
              "Soil_Type36                           -0.005302    -0.000982    -0.002120   \n",
              "Soil_Type37                           -0.009784    -0.001812    -0.003912   \n",
              "Soil_Type38                           -0.046350    -0.008585    -0.018535   \n",
              "Soil_Type39                           -0.043924    -0.008136    -0.017565   \n",
              "Soil_Type40                           -0.036465    -0.006754    -0.014582   \n",
              "Cover_Type                            -0.078955    -0.003470     0.114327   \n",
              "\n",
              "                                    Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
              "Id                                     0.009110     0.016040     0.086932   \n",
              "Elevation                              0.040554     0.073433     0.321949   \n",
              "Aspect                                 0.010398    -0.051523     0.043918   \n",
              "Slope                                 -0.001527     0.004761    -0.154715   \n",
              "Horizontal_Distance_To_Hydrology       0.042023    -0.017976     0.081793   \n",
              "Vertical_Distance_To_Hydrology         0.025059    -0.028168    -0.018610   \n",
              "Horizontal_Distance_To_Roadways        0.032179     0.062208     0.205165   \n",
              "Hillshade_9am                          0.013432     0.006541    -0.016841   \n",
              "Hillshade_Noon                         0.034402    -0.037890     0.103441   \n",
              "Hillshade_3pm                          0.004303    -0.030732     0.071472   \n",
              "Horizontal_Distance_To_Fire_Points    -0.005235     0.048216     0.098326   \n",
              "Wilderness_Area1                      -0.014373     0.065294     0.033239   \n",
              "Wilderness_Area2                      -0.004753    -0.008770     0.084694   \n",
              "Wilderness_Area3                       0.030237    -0.023416     0.081568   \n",
              "Wilderness_Area4                      -0.017211    -0.031761    -0.150467   \n",
              "Soil_Type1                            -0.003989    -0.007361    -0.034874   \n",
              "Soil_Type2                            -0.005333    -0.009841    -0.046624   \n",
              "Soil_Type3                            -0.006706    -0.012375    -0.058626   \n",
              "Soil_Type4                            -0.006251    -0.011536    -0.054651   \n",
              "Soil_Type5                            -0.002702    -0.004987    -0.023624   \n",
              "Soil_Type6                            -0.005452    -0.010062    -0.047668   \n",
              "Soil_Type7                                  NaN          NaN          NaN   \n",
              "Soil_Type8                            -0.000209    -0.000386    -0.001829   \n",
              "Soil_Type9                            -0.000662    -0.001221    -0.005786   \n",
              "Soil_Type10                           -0.010451    -0.019287    -0.091372   \n",
              "Soil_Type11                           -0.004273    -0.007886    -0.037360   \n",
              "Soil_Type12                           -0.003176    -0.005861    -0.027767   \n",
              "Soil_Type13                           -0.004638    -0.008559    -0.040549   \n",
              "Soil_Type14                           -0.002735    -0.005047    -0.023912   \n",
              "Soil_Type15                                 NaN          NaN          NaN   \n",
              "Soil_Type16                           -0.002242    -0.004138    -0.019603   \n",
              "Soil_Type17                           -0.005284    -0.009750    -0.046193   \n",
              "Soil_Type18                           -0.001624    -0.002997    -0.014196   \n",
              "Soil_Type19                           -0.001421    -0.002623    -0.012424   \n",
              "Soil_Type20                           -0.002478    -0.004573    -0.021664   \n",
              "Soil_Type21                           -0.000837    -0.001545    -0.007320   \n",
              "Soil_Type22                           -0.003931    -0.007254    -0.034368   \n",
              "Soil_Type23                           -0.005906    -0.010899    -0.051633   \n",
              "Soil_Type24                           -0.003383    -0.006243    -0.029575   \n",
              "Soil_Type25                           -0.000209    -0.000386    -0.001829   \n",
              "Soil_Type26                           -0.001540    -0.002842    -0.013465   \n",
              "Soil_Type27                           -0.000811    -0.001496    -0.007087   \n",
              "Soil_Type28                           -0.000628    -0.001159    -0.005489   \n",
              "Soil_Type29                           -0.007860    -0.014505    -0.068718   \n",
              "Soil_Type30                           -0.005773    -0.010654    -0.050474   \n",
              "Soil_Type31                           -0.003855    -0.007113    -0.033699   \n",
              "Soil_Type32                           -0.005625    -0.010381    -0.049181   \n",
              "Soil_Type33                           -0.005302    -0.009784    -0.046350   \n",
              "Soil_Type34                           -0.000982    -0.001812    -0.008585   \n",
              "Soil_Type35                           -0.002120    -0.003912    -0.018535   \n",
              "Soil_Type36                            1.000000    -0.001221    -0.005786   \n",
              "Soil_Type37                           -0.001221     1.000000    -0.010677   \n",
              "Soil_Type38                           -0.005786    -0.010677     1.000000   \n",
              "Soil_Type39                           -0.005483    -0.010118    -0.047936   \n",
              "Soil_Type40                           -0.004552    -0.008400    -0.039795   \n",
              "Cover_Type                             0.025726     0.071210     0.257810   \n",
              "\n",
              "                                    Soil_Type39  Soil_Type40  Cover_Type  \n",
              "Id                                     0.083376     0.122475    0.108363  \n",
              "Elevation                              0.294134     0.281407    0.004112  \n",
              "Aspect                                -0.032364    -0.006624    0.003701  \n",
              "Slope                                  0.056108    -0.039752    0.095533  \n",
              "Horizontal_Distance_To_Hydrology       0.076257     0.183069   -0.050755  \n",
              "Vertical_Distance_To_Hydrology         0.061113     0.153158    0.049991  \n",
              "Horizontal_Distance_To_Roadways        0.161078     0.142089   -0.064658  \n",
              "Hillshade_9am                          0.034610    -0.038669   -0.003138  \n",
              "Hillshade_Noon                        -0.072378    -0.026886   -0.099153  \n",
              "Hillshade_3pm                         -0.062608     0.025373   -0.044096  \n",
              "Horizontal_Distance_To_Fire_Points     0.063765     0.134842   -0.058668  \n",
              "Wilderness_Area1                       0.022629    -0.007419   -0.230117  \n",
              "Wilderness_Area2                       0.029631     0.275887    0.014994  \n",
              "Wilderness_Area3                       0.103275     0.017388    0.122146  \n",
              "Wilderness_Area4                      -0.142590    -0.118375    0.075774  \n",
              "Soil_Type1                            -0.033048    -0.027436    0.015069  \n",
              "Soil_Type2                            -0.044183    -0.036680    0.022627  \n",
              "Soil_Type3                            -0.055557    -0.046122   -0.016393  \n",
              "Soil_Type4                            -0.051790    -0.042995   -0.027816  \n",
              "Soil_Type5                            -0.022387    -0.018585    0.027692  \n",
              "Soil_Type6                            -0.045173    -0.037501    0.006521  \n",
              "Soil_Type7                                  NaN          NaN         NaN  \n",
              "Soil_Type8                            -0.001733    -0.001439   -0.008133  \n",
              "Soil_Type9                            -0.005483    -0.004552   -0.027012  \n",
              "Soil_Type10                           -0.086588    -0.071884    0.128972  \n",
              "Soil_Type11                           -0.035404    -0.029392    0.010228  \n",
              "Soil_Type12                           -0.026313    -0.021845   -0.129985  \n",
              "Soil_Type13                           -0.038426    -0.031901    0.040528  \n",
              "Soil_Type14                           -0.022660    -0.018812    0.022019  \n",
              "Soil_Type15                                 NaN          NaN         NaN  \n",
              "Soil_Type16                           -0.018577    -0.015422    0.008793  \n",
              "Soil_Type17                           -0.043775    -0.036341    0.042453  \n",
              "Soil_Type18                           -0.013453    -0.011168    0.006312  \n",
              "Soil_Type19                           -0.011774    -0.009774   -0.031824  \n",
              "Soil_Type20                           -0.020530    -0.017044   -0.053013  \n",
              "Soil_Type21                           -0.006937    -0.005759   -0.024410  \n",
              "Soil_Type22                           -0.032569    -0.027038   -0.195993  \n",
              "Soil_Type23                           -0.048930    -0.040621   -0.158762  \n",
              "Soil_Type24                           -0.028026    -0.023267   -0.100797  \n",
              "Soil_Type25                           -0.001733    -0.001439   -0.008133  \n",
              "Soil_Type26                           -0.012760    -0.010593   -0.017184  \n",
              "Soil_Type27                           -0.006716    -0.005576   -0.023109  \n",
              "Soil_Type28                           -0.005201    -0.004318   -0.012202  \n",
              "Soil_Type29                           -0.065121    -0.054062   -0.218564  \n",
              "Soil_Type30                           -0.047832    -0.039709    0.001393  \n",
              "Soil_Type31                           -0.031935    -0.026512   -0.079882  \n",
              "Soil_Type32                           -0.046606    -0.038692   -0.132312  \n",
              "Soil_Type33                           -0.043924    -0.036465   -0.078955  \n",
              "Soil_Type34                           -0.008136    -0.006754   -0.003470  \n",
              "Soil_Type35                           -0.017565    -0.014582    0.114327  \n",
              "Soil_Type36                           -0.005483    -0.004552    0.025726  \n",
              "Soil_Type37                           -0.010118    -0.008400    0.071210  \n",
              "Soil_Type38                           -0.047936    -0.039795    0.257810  \n",
              "Soil_Type39                            1.000000    -0.037712    0.240384  \n",
              "Soil_Type40                           -0.037712     1.000000    0.205851  \n",
              "Cover_Type                             0.240384     0.205851    1.000000  \n",
              "\n",
              "[56 rows x 56 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f3fcdaf-0d0c-4f13-bdb6-b4ae5fd1eaa2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Aspect</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <th>Hillshade_9am</th>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <th>Hillshade_3pm</th>\n",
              "      <th>...</th>\n",
              "      <th>Soil_Type32</th>\n",
              "      <th>Soil_Type33</th>\n",
              "      <th>Soil_Type34</th>\n",
              "      <th>Soil_Type35</th>\n",
              "      <th>Soil_Type36</th>\n",
              "      <th>Soil_Type37</th>\n",
              "      <th>Soil_Type38</th>\n",
              "      <th>Soil_Type39</th>\n",
              "      <th>Soil_Type40</th>\n",
              "      <th>Cover_Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Id</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.180974</td>\n",
              "      <td>0.023739</td>\n",
              "      <td>-0.004949</td>\n",
              "      <td>0.071122</td>\n",
              "      <td>0.036881</td>\n",
              "      <td>0.053789</td>\n",
              "      <td>-0.016026</td>\n",
              "      <td>0.060624</td>\n",
              "      <td>0.035596</td>\n",
              "      <td>...</td>\n",
              "      <td>0.068048</td>\n",
              "      <td>0.066887</td>\n",
              "      <td>0.022520</td>\n",
              "      <td>0.057480</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.016040</td>\n",
              "      <td>0.086932</td>\n",
              "      <td>0.083376</td>\n",
              "      <td>0.122475</td>\n",
              "      <td>0.108363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Elevation</th>\n",
              "      <td>0.180974</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.008893</td>\n",
              "      <td>-0.307724</td>\n",
              "      <td>0.382550</td>\n",
              "      <td>0.092769</td>\n",
              "      <td>0.596820</td>\n",
              "      <td>0.024188</td>\n",
              "      <td>0.203171</td>\n",
              "      <td>0.086092</td>\n",
              "      <td>...</td>\n",
              "      <td>0.177010</td>\n",
              "      <td>0.127712</td>\n",
              "      <td>0.023214</td>\n",
              "      <td>0.119577</td>\n",
              "      <td>0.040554</td>\n",
              "      <td>0.073433</td>\n",
              "      <td>0.321949</td>\n",
              "      <td>0.294134</td>\n",
              "      <td>0.281407</td>\n",
              "      <td>0.004112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Aspect</th>\n",
              "      <td>0.023739</td>\n",
              "      <td>-0.008893</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.046002</td>\n",
              "      <td>0.034378</td>\n",
              "      <td>0.071070</td>\n",
              "      <td>0.072618</td>\n",
              "      <td>-0.419927</td>\n",
              "      <td>0.402474</td>\n",
              "      <td>0.627344</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.018728</td>\n",
              "      <td>0.016168</td>\n",
              "      <td>0.002710</td>\n",
              "      <td>0.010398</td>\n",
              "      <td>-0.051523</td>\n",
              "      <td>0.043918</td>\n",
              "      <td>-0.032364</td>\n",
              "      <td>-0.006624</td>\n",
              "      <td>0.003701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Slope</th>\n",
              "      <td>-0.004949</td>\n",
              "      <td>-0.307724</td>\n",
              "      <td>0.046002</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.025893</td>\n",
              "      <td>0.333128</td>\n",
              "      <td>-0.275328</td>\n",
              "      <td>-0.010455</td>\n",
              "      <td>-0.536903</td>\n",
              "      <td>-0.283618</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.152895</td>\n",
              "      <td>0.085263</td>\n",
              "      <td>-0.032372</td>\n",
              "      <td>-0.050070</td>\n",
              "      <td>-0.001527</td>\n",
              "      <td>0.004761</td>\n",
              "      <td>-0.154715</td>\n",
              "      <td>0.056108</td>\n",
              "      <td>-0.039752</td>\n",
              "      <td>0.095533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <td>0.071122</td>\n",
              "      <td>0.382550</td>\n",
              "      <td>0.034378</td>\n",
              "      <td>0.025893</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.695442</td>\n",
              "      <td>0.139846</td>\n",
              "      <td>-0.044380</td>\n",
              "      <td>0.031262</td>\n",
              "      <td>0.049454</td>\n",
              "      <td>...</td>\n",
              "      <td>0.152044</td>\n",
              "      <td>0.070031</td>\n",
              "      <td>0.045031</td>\n",
              "      <td>-0.033122</td>\n",
              "      <td>0.042023</td>\n",
              "      <td>-0.017976</td>\n",
              "      <td>0.081793</td>\n",
              "      <td>0.076257</td>\n",
              "      <td>0.183069</td>\n",
              "      <td>-0.050755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <td>0.036881</td>\n",
              "      <td>0.092769</td>\n",
              "      <td>0.071070</td>\n",
              "      <td>0.333128</td>\n",
              "      <td>0.695442</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.025484</td>\n",
              "      <td>-0.054841</td>\n",
              "      <td>-0.148982</td>\n",
              "      <td>-0.029066</td>\n",
              "      <td>...</td>\n",
              "      <td>0.041557</td>\n",
              "      <td>0.080899</td>\n",
              "      <td>0.022227</td>\n",
              "      <td>-0.046257</td>\n",
              "      <td>0.025059</td>\n",
              "      <td>-0.028168</td>\n",
              "      <td>-0.018610</td>\n",
              "      <td>0.061113</td>\n",
              "      <td>0.153158</td>\n",
              "      <td>0.049991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <td>0.053789</td>\n",
              "      <td>0.596820</td>\n",
              "      <td>0.072618</td>\n",
              "      <td>-0.275328</td>\n",
              "      <td>0.139846</td>\n",
              "      <td>-0.025484</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.067327</td>\n",
              "      <td>0.251642</td>\n",
              "      <td>0.182770</td>\n",
              "      <td>...</td>\n",
              "      <td>0.073202</td>\n",
              "      <td>0.074930</td>\n",
              "      <td>0.028308</td>\n",
              "      <td>0.081723</td>\n",
              "      <td>0.032179</td>\n",
              "      <td>0.062208</td>\n",
              "      <td>0.205165</td>\n",
              "      <td>0.161078</td>\n",
              "      <td>0.142089</td>\n",
              "      <td>-0.064658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hillshade_9am</th>\n",
              "      <td>-0.016026</td>\n",
              "      <td>0.024188</td>\n",
              "      <td>-0.419927</td>\n",
              "      <td>-0.010455</td>\n",
              "      <td>-0.044380</td>\n",
              "      <td>-0.054841</td>\n",
              "      <td>-0.067327</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.135688</td>\n",
              "      <td>-0.835658</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.013400</td>\n",
              "      <td>-0.034492</td>\n",
              "      <td>-0.003051</td>\n",
              "      <td>0.027107</td>\n",
              "      <td>0.013432</td>\n",
              "      <td>0.006541</td>\n",
              "      <td>-0.016841</td>\n",
              "      <td>0.034610</td>\n",
              "      <td>-0.038669</td>\n",
              "      <td>-0.003138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <td>0.060624</td>\n",
              "      <td>0.203171</td>\n",
              "      <td>0.402474</td>\n",
              "      <td>-0.536903</td>\n",
              "      <td>0.031262</td>\n",
              "      <td>-0.148982</td>\n",
              "      <td>0.251642</td>\n",
              "      <td>-0.135688</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.582819</td>\n",
              "      <td>...</td>\n",
              "      <td>0.096333</td>\n",
              "      <td>-0.014229</td>\n",
              "      <td>0.038619</td>\n",
              "      <td>0.035543</td>\n",
              "      <td>0.034402</td>\n",
              "      <td>-0.037890</td>\n",
              "      <td>0.103441</td>\n",
              "      <td>-0.072378</td>\n",
              "      <td>-0.026886</td>\n",
              "      <td>-0.099153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hillshade_3pm</th>\n",
              "      <td>0.035596</td>\n",
              "      <td>0.086092</td>\n",
              "      <td>0.627344</td>\n",
              "      <td>-0.283618</td>\n",
              "      <td>0.049454</td>\n",
              "      <td>-0.029066</td>\n",
              "      <td>0.182770</td>\n",
              "      <td>-0.835658</td>\n",
              "      <td>0.582819</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.059921</td>\n",
              "      <td>0.016483</td>\n",
              "      <td>0.021390</td>\n",
              "      <td>-0.002470</td>\n",
              "      <td>0.004303</td>\n",
              "      <td>-0.030732</td>\n",
              "      <td>0.071472</td>\n",
              "      <td>-0.062608</td>\n",
              "      <td>0.025373</td>\n",
              "      <td>-0.044096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
              "      <td>-0.004136</td>\n",
              "      <td>0.508872</td>\n",
              "      <td>-0.059489</td>\n",
              "      <td>-0.235185</td>\n",
              "      <td>0.185253</td>\n",
              "      <td>0.009458</td>\n",
              "      <td>0.421900</td>\n",
              "      <td>0.038279</td>\n",
              "      <td>0.103556</td>\n",
              "      <td>0.029902</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056947</td>\n",
              "      <td>0.071669</td>\n",
              "      <td>-0.003391</td>\n",
              "      <td>-0.004230</td>\n",
              "      <td>-0.005235</td>\n",
              "      <td>0.048216</td>\n",
              "      <td>0.098326</td>\n",
              "      <td>0.063765</td>\n",
              "      <td>0.134842</td>\n",
              "      <td>-0.058668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wilderness_Area1</th>\n",
              "      <td>-0.339861</td>\n",
              "      <td>0.338674</td>\n",
              "      <td>-0.123979</td>\n",
              "      <td>-0.160766</td>\n",
              "      <td>0.030364</td>\n",
              "      <td>-0.103723</td>\n",
              "      <td>0.248010</td>\n",
              "      <td>0.161057</td>\n",
              "      <td>-0.011370</td>\n",
              "      <td>-0.123404</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.122174</td>\n",
              "      <td>-0.115142</td>\n",
              "      <td>-0.021327</td>\n",
              "      <td>0.007086</td>\n",
              "      <td>-0.014373</td>\n",
              "      <td>0.065294</td>\n",
              "      <td>0.033239</td>\n",
              "      <td>0.022629</td>\n",
              "      <td>-0.007419</td>\n",
              "      <td>-0.230117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wilderness_Area2</th>\n",
              "      <td>0.158484</td>\n",
              "      <td>0.254770</td>\n",
              "      <td>0.022381</td>\n",
              "      <td>-0.063539</td>\n",
              "      <td>0.091548</td>\n",
              "      <td>0.011631</td>\n",
              "      <td>-0.062155</td>\n",
              "      <td>-0.019120</td>\n",
              "      <td>0.029332</td>\n",
              "      <td>0.037945</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023467</td>\n",
              "      <td>0.025601</td>\n",
              "      <td>-0.007052</td>\n",
              "      <td>0.011912</td>\n",
              "      <td>-0.004753</td>\n",
              "      <td>-0.008770</td>\n",
              "      <td>0.084694</td>\n",
              "      <td>0.029631</td>\n",
              "      <td>0.275887</td>\n",
              "      <td>0.014994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wilderness_Area3</th>\n",
              "      <td>0.384219</td>\n",
              "      <td>0.358016</td>\n",
              "      <td>0.037047</td>\n",
              "      <td>-0.097961</td>\n",
              "      <td>0.165121</td>\n",
              "      <td>0.060976</td>\n",
              "      <td>0.259070</td>\n",
              "      <td>-0.073365</td>\n",
              "      <td>0.183425</td>\n",
              "      <td>0.127071</td>\n",
              "      <td>...</td>\n",
              "      <td>0.233901</td>\n",
              "      <td>0.219177</td>\n",
              "      <td>0.044867</td>\n",
              "      <td>0.041204</td>\n",
              "      <td>0.030237</td>\n",
              "      <td>-0.023416</td>\n",
              "      <td>0.081568</td>\n",
              "      <td>0.103275</td>\n",
              "      <td>0.017388</td>\n",
              "      <td>0.122146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wilderness_Area4</th>\n",
              "      <td>-0.158451</td>\n",
              "      <td>-0.792831</td>\n",
              "      <td>0.066010</td>\n",
              "      <td>0.277289</td>\n",
              "      <td>-0.239695</td>\n",
              "      <td>0.025950</td>\n",
              "      <td>-0.481132</td>\n",
              "      <td>-0.062647</td>\n",
              "      <td>-0.196743</td>\n",
              "      <td>-0.036673</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.146294</td>\n",
              "      <td>-0.137874</td>\n",
              "      <td>-0.025538</td>\n",
              "      <td>-0.055135</td>\n",
              "      <td>-0.017211</td>\n",
              "      <td>-0.031761</td>\n",
              "      <td>-0.150467</td>\n",
              "      <td>-0.142590</td>\n",
              "      <td>-0.118375</td>\n",
              "      <td>0.075774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type1</th>\n",
              "      <td>-0.058451</td>\n",
              "      <td>-0.217966</td>\n",
              "      <td>-0.014050</td>\n",
              "      <td>0.101050</td>\n",
              "      <td>-0.097272</td>\n",
              "      <td>-0.040180</td>\n",
              "      <td>-0.150565</td>\n",
              "      <td>0.042056</td>\n",
              "      <td>-0.017270</td>\n",
              "      <td>-0.058902</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.033907</td>\n",
              "      <td>-0.031955</td>\n",
              "      <td>-0.005919</td>\n",
              "      <td>-0.012779</td>\n",
              "      <td>-0.003989</td>\n",
              "      <td>-0.007361</td>\n",
              "      <td>-0.034874</td>\n",
              "      <td>-0.033048</td>\n",
              "      <td>-0.027436</td>\n",
              "      <td>0.015069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type2</th>\n",
              "      <td>0.045545</td>\n",
              "      <td>-0.149352</td>\n",
              "      <td>-0.006420</td>\n",
              "      <td>-0.078279</td>\n",
              "      <td>0.056110</td>\n",
              "      <td>0.021591</td>\n",
              "      <td>-0.074768</td>\n",
              "      <td>0.049014</td>\n",
              "      <td>0.088938</td>\n",
              "      <td>0.005238</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.045331</td>\n",
              "      <td>-0.042722</td>\n",
              "      <td>-0.007913</td>\n",
              "      <td>-0.017084</td>\n",
              "      <td>-0.005333</td>\n",
              "      <td>-0.009841</td>\n",
              "      <td>-0.046624</td>\n",
              "      <td>-0.044183</td>\n",
              "      <td>-0.036680</td>\n",
              "      <td>0.022627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type3</th>\n",
              "      <td>-0.045757</td>\n",
              "      <td>-0.316436</td>\n",
              "      <td>-0.014578</td>\n",
              "      <td>0.246474</td>\n",
              "      <td>-0.071691</td>\n",
              "      <td>0.095937</td>\n",
              "      <td>-0.165107</td>\n",
              "      <td>0.301526</td>\n",
              "      <td>-0.105215</td>\n",
              "      <td>-0.264907</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.057000</td>\n",
              "      <td>-0.053720</td>\n",
              "      <td>-0.009950</td>\n",
              "      <td>-0.021482</td>\n",
              "      <td>-0.006706</td>\n",
              "      <td>-0.012375</td>\n",
              "      <td>-0.058626</td>\n",
              "      <td>-0.055557</td>\n",
              "      <td>-0.046122</td>\n",
              "      <td>-0.016393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type4</th>\n",
              "      <td>0.118214</td>\n",
              "      <td>-0.125560</td>\n",
              "      <td>0.054990</td>\n",
              "      <td>0.099734</td>\n",
              "      <td>-0.054540</td>\n",
              "      <td>-0.012786</td>\n",
              "      <td>-0.076162</td>\n",
              "      <td>0.040495</td>\n",
              "      <td>0.166102</td>\n",
              "      <td>0.016398</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.053136</td>\n",
              "      <td>-0.050077</td>\n",
              "      <td>-0.009276</td>\n",
              "      <td>-0.020026</td>\n",
              "      <td>-0.006251</td>\n",
              "      <td>-0.011536</td>\n",
              "      <td>-0.054651</td>\n",
              "      <td>-0.051790</td>\n",
              "      <td>-0.042995</td>\n",
              "      <td>-0.027816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type5</th>\n",
              "      <td>-0.041713</td>\n",
              "      <td>-0.138551</td>\n",
              "      <td>-0.009963</td>\n",
              "      <td>0.070435</td>\n",
              "      <td>-0.021528</td>\n",
              "      <td>0.017048</td>\n",
              "      <td>-0.118069</td>\n",
              "      <td>-0.040538</td>\n",
              "      <td>-0.078700</td>\n",
              "      <td>-0.016228</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.022969</td>\n",
              "      <td>-0.021647</td>\n",
              "      <td>-0.004010</td>\n",
              "      <td>-0.008657</td>\n",
              "      <td>-0.002702</td>\n",
              "      <td>-0.004987</td>\n",
              "      <td>-0.023624</td>\n",
              "      <td>-0.022387</td>\n",
              "      <td>-0.018585</td>\n",
              "      <td>0.027692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type6</th>\n",
              "      <td>-0.046017</td>\n",
              "      <td>-0.184140</td>\n",
              "      <td>-0.005831</td>\n",
              "      <td>-0.044602</td>\n",
              "      <td>0.051428</td>\n",
              "      <td>0.095840</td>\n",
              "      <td>-0.144926</td>\n",
              "      <td>0.014107</td>\n",
              "      <td>0.019206</td>\n",
              "      <td>0.001240</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.046346</td>\n",
              "      <td>-0.043679</td>\n",
              "      <td>-0.008090</td>\n",
              "      <td>-0.017467</td>\n",
              "      <td>-0.005452</td>\n",
              "      <td>-0.010062</td>\n",
              "      <td>-0.047668</td>\n",
              "      <td>-0.045173</td>\n",
              "      <td>-0.037501</td>\n",
              "      <td>0.006521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type7</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type8</th>\n",
              "      <td>-0.013159</td>\n",
              "      <td>0.003649</td>\n",
              "      <td>0.003878</td>\n",
              "      <td>-0.013495</td>\n",
              "      <td>0.006004</td>\n",
              "      <td>-0.012317</td>\n",
              "      <td>0.012802</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.009383</td>\n",
              "      <td>0.004602</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001778</td>\n",
              "      <td>-0.001676</td>\n",
              "      <td>-0.000310</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>-0.000209</td>\n",
              "      <td>-0.000386</td>\n",
              "      <td>-0.001829</td>\n",
              "      <td>-0.001733</td>\n",
              "      <td>-0.001439</td>\n",
              "      <td>-0.008133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type9</th>\n",
              "      <td>-0.014219</td>\n",
              "      <td>-0.010578</td>\n",
              "      <td>-0.021238</td>\n",
              "      <td>-0.022186</td>\n",
              "      <td>-0.001103</td>\n",
              "      <td>-0.016549</td>\n",
              "      <td>-0.022715</td>\n",
              "      <td>0.002238</td>\n",
              "      <td>0.001449</td>\n",
              "      <td>-0.002371</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.005625</td>\n",
              "      <td>-0.005302</td>\n",
              "      <td>-0.000982</td>\n",
              "      <td>-0.002120</td>\n",
              "      <td>-0.000662</td>\n",
              "      <td>-0.001221</td>\n",
              "      <td>-0.005786</td>\n",
              "      <td>-0.005483</td>\n",
              "      <td>-0.004552</td>\n",
              "      <td>-0.027012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type10</th>\n",
              "      <td>0.032292</td>\n",
              "      <td>-0.360877</td>\n",
              "      <td>0.052599</td>\n",
              "      <td>0.261403</td>\n",
              "      <td>-0.081998</td>\n",
              "      <td>0.055891</td>\n",
              "      <td>-0.212776</td>\n",
              "      <td>-0.331203</td>\n",
              "      <td>-0.271683</td>\n",
              "      <td>0.118730</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.088838</td>\n",
              "      <td>-0.083724</td>\n",
              "      <td>-0.015508</td>\n",
              "      <td>-0.033481</td>\n",
              "      <td>-0.010451</td>\n",
              "      <td>-0.019287</td>\n",
              "      <td>-0.091372</td>\n",
              "      <td>-0.086588</td>\n",
              "      <td>-0.071884</td>\n",
              "      <td>0.128972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type11</th>\n",
              "      <td>0.063372</td>\n",
              "      <td>-0.037197</td>\n",
              "      <td>-0.040827</td>\n",
              "      <td>-0.113955</td>\n",
              "      <td>0.035057</td>\n",
              "      <td>-0.013766</td>\n",
              "      <td>-0.077586</td>\n",
              "      <td>0.006689</td>\n",
              "      <td>0.024886</td>\n",
              "      <td>0.011609</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.036324</td>\n",
              "      <td>-0.034233</td>\n",
              "      <td>-0.006341</td>\n",
              "      <td>-0.013690</td>\n",
              "      <td>-0.004273</td>\n",
              "      <td>-0.007886</td>\n",
              "      <td>-0.037360</td>\n",
              "      <td>-0.035404</td>\n",
              "      <td>-0.029392</td>\n",
              "      <td>0.010228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type12</th>\n",
              "      <td>-0.129930</td>\n",
              "      <td>0.019909</td>\n",
              "      <td>-0.040888</td>\n",
              "      <td>-0.124104</td>\n",
              "      <td>0.054548</td>\n",
              "      <td>-0.016643</td>\n",
              "      <td>0.082255</td>\n",
              "      <td>0.033838</td>\n",
              "      <td>0.050942</td>\n",
              "      <td>0.001247</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.026997</td>\n",
              "      <td>-0.025443</td>\n",
              "      <td>-0.004713</td>\n",
              "      <td>-0.010175</td>\n",
              "      <td>-0.003176</td>\n",
              "      <td>-0.005861</td>\n",
              "      <td>-0.027767</td>\n",
              "      <td>-0.026313</td>\n",
              "      <td>-0.021845</td>\n",
              "      <td>-0.129985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type13</th>\n",
              "      <td>0.015145</td>\n",
              "      <td>0.046983</td>\n",
              "      <td>0.041842</td>\n",
              "      <td>0.129632</td>\n",
              "      <td>0.036216</td>\n",
              "      <td>0.092643</td>\n",
              "      <td>0.055979</td>\n",
              "      <td>0.046697</td>\n",
              "      <td>0.002466</td>\n",
              "      <td>-0.029227</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.039424</td>\n",
              "      <td>-0.037155</td>\n",
              "      <td>-0.006882</td>\n",
              "      <td>-0.014858</td>\n",
              "      <td>-0.004638</td>\n",
              "      <td>-0.008559</td>\n",
              "      <td>-0.040549</td>\n",
              "      <td>-0.038426</td>\n",
              "      <td>-0.031901</td>\n",
              "      <td>0.040528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type14</th>\n",
              "      <td>-0.016034</td>\n",
              "      <td>-0.143683</td>\n",
              "      <td>-0.006563</td>\n",
              "      <td>-0.054104</td>\n",
              "      <td>-0.157802</td>\n",
              "      <td>-0.127907</td>\n",
              "      <td>-0.079801</td>\n",
              "      <td>-0.018760</td>\n",
              "      <td>0.000482</td>\n",
              "      <td>0.018319</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.023249</td>\n",
              "      <td>-0.021911</td>\n",
              "      <td>-0.004058</td>\n",
              "      <td>-0.008762</td>\n",
              "      <td>-0.002735</td>\n",
              "      <td>-0.005047</td>\n",
              "      <td>-0.023912</td>\n",
              "      <td>-0.022660</td>\n",
              "      <td>-0.018812</td>\n",
              "      <td>0.022019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type15</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type16</th>\n",
              "      <td>-0.003794</td>\n",
              "      <td>-0.066457</td>\n",
              "      <td>0.024807</td>\n",
              "      <td>-0.067588</td>\n",
              "      <td>-0.116091</td>\n",
              "      <td>-0.099319</td>\n",
              "      <td>-0.019780</td>\n",
              "      <td>-0.017119</td>\n",
              "      <td>0.046196</td>\n",
              "      <td>0.039931</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.019059</td>\n",
              "      <td>-0.017962</td>\n",
              "      <td>-0.003327</td>\n",
              "      <td>-0.007183</td>\n",
              "      <td>-0.002242</td>\n",
              "      <td>-0.004138</td>\n",
              "      <td>-0.019603</td>\n",
              "      <td>-0.018577</td>\n",
              "      <td>-0.015422</td>\n",
              "      <td>0.008793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type17</th>\n",
              "      <td>-0.002940</td>\n",
              "      <td>-0.203990</td>\n",
              "      <td>0.023699</td>\n",
              "      <td>-0.130424</td>\n",
              "      <td>-0.233485</td>\n",
              "      <td>-0.216830</td>\n",
              "      <td>-0.051390</td>\n",
              "      <td>-0.047580</td>\n",
              "      <td>0.086260</td>\n",
              "      <td>0.082756</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.044912</td>\n",
              "      <td>-0.042327</td>\n",
              "      <td>-0.007840</td>\n",
              "      <td>-0.016926</td>\n",
              "      <td>-0.005284</td>\n",
              "      <td>-0.009750</td>\n",
              "      <td>-0.046193</td>\n",
              "      <td>-0.043775</td>\n",
              "      <td>-0.036341</td>\n",
              "      <td>0.042453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type18</th>\n",
              "      <td>-0.070252</td>\n",
              "      <td>-0.034106</td>\n",
              "      <td>-0.042153</td>\n",
              "      <td>-0.077490</td>\n",
              "      <td>-0.009517</td>\n",
              "      <td>-0.043664</td>\n",
              "      <td>-0.045777</td>\n",
              "      <td>0.019033</td>\n",
              "      <td>0.023946</td>\n",
              "      <td>-0.001296</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.013802</td>\n",
              "      <td>-0.013008</td>\n",
              "      <td>-0.002409</td>\n",
              "      <td>-0.005202</td>\n",
              "      <td>-0.001624</td>\n",
              "      <td>-0.002997</td>\n",
              "      <td>-0.014196</td>\n",
              "      <td>-0.013453</td>\n",
              "      <td>-0.011168</td>\n",
              "      <td>0.006312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type19</th>\n",
              "      <td>-0.029707</td>\n",
              "      <td>0.032369</td>\n",
              "      <td>0.004654</td>\n",
              "      <td>-0.050617</td>\n",
              "      <td>-0.043054</td>\n",
              "      <td>-0.053157</td>\n",
              "      <td>0.050708</td>\n",
              "      <td>-0.014371</td>\n",
              "      <td>0.038726</td>\n",
              "      <td>0.030854</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.012080</td>\n",
              "      <td>-0.011384</td>\n",
              "      <td>-0.002109</td>\n",
              "      <td>-0.004553</td>\n",
              "      <td>-0.001421</td>\n",
              "      <td>-0.002623</td>\n",
              "      <td>-0.012424</td>\n",
              "      <td>-0.011774</td>\n",
              "      <td>-0.009774</td>\n",
              "      <td>-0.031824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type20</th>\n",
              "      <td>-0.069537</td>\n",
              "      <td>0.010290</td>\n",
              "      <td>-0.030183</td>\n",
              "      <td>-0.071671</td>\n",
              "      <td>-0.089375</td>\n",
              "      <td>-0.092467</td>\n",
              "      <td>0.043680</td>\n",
              "      <td>-0.006872</td>\n",
              "      <td>0.011346</td>\n",
              "      <td>0.009797</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.021063</td>\n",
              "      <td>-0.019851</td>\n",
              "      <td>-0.003677</td>\n",
              "      <td>-0.007938</td>\n",
              "      <td>-0.002478</td>\n",
              "      <td>-0.004573</td>\n",
              "      <td>-0.021664</td>\n",
              "      <td>-0.020530</td>\n",
              "      <td>-0.017044</td>\n",
              "      <td>-0.053013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type21</th>\n",
              "      <td>0.014734</td>\n",
              "      <td>0.032750</td>\n",
              "      <td>0.018012</td>\n",
              "      <td>-0.037301</td>\n",
              "      <td>-0.031302</td>\n",
              "      <td>-0.025833</td>\n",
              "      <td>0.004895</td>\n",
              "      <td>-0.015088</td>\n",
              "      <td>0.031807</td>\n",
              "      <td>0.028361</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.007117</td>\n",
              "      <td>-0.006707</td>\n",
              "      <td>-0.001242</td>\n",
              "      <td>-0.002682</td>\n",
              "      <td>-0.000837</td>\n",
              "      <td>-0.001545</td>\n",
              "      <td>-0.007320</td>\n",
              "      <td>-0.006937</td>\n",
              "      <td>-0.005759</td>\n",
              "      <td>-0.024410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type22</th>\n",
              "      <td>0.035739</td>\n",
              "      <td>0.146604</td>\n",
              "      <td>0.018103</td>\n",
              "      <td>-0.076289</td>\n",
              "      <td>0.008889</td>\n",
              "      <td>-0.064589</td>\n",
              "      <td>0.070697</td>\n",
              "      <td>-0.018078</td>\n",
              "      <td>0.053536</td>\n",
              "      <td>0.041999</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.033415</td>\n",
              "      <td>-0.031491</td>\n",
              "      <td>-0.005833</td>\n",
              "      <td>-0.012593</td>\n",
              "      <td>-0.003931</td>\n",
              "      <td>-0.007254</td>\n",
              "      <td>-0.034368</td>\n",
              "      <td>-0.032569</td>\n",
              "      <td>-0.027038</td>\n",
              "      <td>-0.195993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type23</th>\n",
              "      <td>-0.017422</td>\n",
              "      <td>0.164661</td>\n",
              "      <td>0.034793</td>\n",
              "      <td>-0.196010</td>\n",
              "      <td>-0.109752</td>\n",
              "      <td>-0.170808</td>\n",
              "      <td>0.131757</td>\n",
              "      <td>-0.043857</td>\n",
              "      <td>0.133959</td>\n",
              "      <td>0.103708</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.050202</td>\n",
              "      <td>-0.047312</td>\n",
              "      <td>-0.008763</td>\n",
              "      <td>-0.018920</td>\n",
              "      <td>-0.005906</td>\n",
              "      <td>-0.010899</td>\n",
              "      <td>-0.051633</td>\n",
              "      <td>-0.048930</td>\n",
              "      <td>-0.040621</td>\n",
              "      <td>-0.158762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type24</th>\n",
              "      <td>0.034019</td>\n",
              "      <td>0.099750</td>\n",
              "      <td>-0.010875</td>\n",
              "      <td>0.032107</td>\n",
              "      <td>0.042611</td>\n",
              "      <td>0.025812</td>\n",
              "      <td>0.026721</td>\n",
              "      <td>-0.057282</td>\n",
              "      <td>-0.072282</td>\n",
              "      <td>0.009329</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028754</td>\n",
              "      <td>-0.027099</td>\n",
              "      <td>-0.005020</td>\n",
              "      <td>-0.010837</td>\n",
              "      <td>-0.003383</td>\n",
              "      <td>-0.006243</td>\n",
              "      <td>-0.029575</td>\n",
              "      <td>-0.028026</td>\n",
              "      <td>-0.023267</td>\n",
              "      <td>-0.100797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type25</th>\n",
              "      <td>0.005675</td>\n",
              "      <td>0.010422</td>\n",
              "      <td>-0.000050</td>\n",
              "      <td>0.010968</td>\n",
              "      <td>-0.004300</td>\n",
              "      <td>-0.013878</td>\n",
              "      <td>-0.008552</td>\n",
              "      <td>0.013547</td>\n",
              "      <td>-0.006672</td>\n",
              "      <td>-0.012023</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001778</td>\n",
              "      <td>-0.001676</td>\n",
              "      <td>-0.000310</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>-0.000209</td>\n",
              "      <td>-0.000386</td>\n",
              "      <td>-0.001829</td>\n",
              "      <td>-0.001733</td>\n",
              "      <td>-0.001439</td>\n",
              "      <td>-0.008133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type26</th>\n",
              "      <td>0.031176</td>\n",
              "      <td>0.024609</td>\n",
              "      <td>-0.000816</td>\n",
              "      <td>-0.030860</td>\n",
              "      <td>0.029898</td>\n",
              "      <td>-0.006292</td>\n",
              "      <td>0.049425</td>\n",
              "      <td>0.018732</td>\n",
              "      <td>0.047315</td>\n",
              "      <td>0.007193</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.013091</td>\n",
              "      <td>-0.012338</td>\n",
              "      <td>-0.002285</td>\n",
              "      <td>-0.004934</td>\n",
              "      <td>-0.001540</td>\n",
              "      <td>-0.002842</td>\n",
              "      <td>-0.013465</td>\n",
              "      <td>-0.012760</td>\n",
              "      <td>-0.010593</td>\n",
              "      <td>-0.017184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type27</th>\n",
              "      <td>0.024141</td>\n",
              "      <td>0.039867</td>\n",
              "      <td>0.021210</td>\n",
              "      <td>0.016634</td>\n",
              "      <td>0.029541</td>\n",
              "      <td>0.023702</td>\n",
              "      <td>0.028277</td>\n",
              "      <td>-0.011914</td>\n",
              "      <td>0.028646</td>\n",
              "      <td>0.021857</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.006891</td>\n",
              "      <td>-0.006494</td>\n",
              "      <td>-0.001203</td>\n",
              "      <td>-0.002597</td>\n",
              "      <td>-0.000811</td>\n",
              "      <td>-0.001496</td>\n",
              "      <td>-0.007087</td>\n",
              "      <td>-0.006716</td>\n",
              "      <td>-0.005576</td>\n",
              "      <td>-0.023109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type28</th>\n",
              "      <td>-0.005104</td>\n",
              "      <td>-0.000803</td>\n",
              "      <td>0.023306</td>\n",
              "      <td>0.030519</td>\n",
              "      <td>0.013313</td>\n",
              "      <td>0.010826</td>\n",
              "      <td>-0.008690</td>\n",
              "      <td>-0.039088</td>\n",
              "      <td>0.008666</td>\n",
              "      <td>0.040561</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.005337</td>\n",
              "      <td>-0.005029</td>\n",
              "      <td>-0.000932</td>\n",
              "      <td>-0.002011</td>\n",
              "      <td>-0.000628</td>\n",
              "      <td>-0.001159</td>\n",
              "      <td>-0.005489</td>\n",
              "      <td>-0.005201</td>\n",
              "      <td>-0.004318</td>\n",
              "      <td>-0.012202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type29</th>\n",
              "      <td>-0.231780</td>\n",
              "      <td>0.173524</td>\n",
              "      <td>-0.066358</td>\n",
              "      <td>-0.078882</td>\n",
              "      <td>0.066650</td>\n",
              "      <td>-0.026890</td>\n",
              "      <td>0.176204</td>\n",
              "      <td>0.043233</td>\n",
              "      <td>-0.010079</td>\n",
              "      <td>-0.040977</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.066813</td>\n",
              "      <td>-0.062967</td>\n",
              "      <td>-0.011663</td>\n",
              "      <td>-0.025180</td>\n",
              "      <td>-0.007860</td>\n",
              "      <td>-0.014505</td>\n",
              "      <td>-0.068718</td>\n",
              "      <td>-0.065121</td>\n",
              "      <td>-0.054062</td>\n",
              "      <td>-0.218564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type30</th>\n",
              "      <td>-0.157515</td>\n",
              "      <td>0.050948</td>\n",
              "      <td>-0.064256</td>\n",
              "      <td>0.116337</td>\n",
              "      <td>-0.003192</td>\n",
              "      <td>0.011829</td>\n",
              "      <td>-0.129635</td>\n",
              "      <td>0.196192</td>\n",
              "      <td>-0.113194</td>\n",
              "      <td>-0.203593</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.049074</td>\n",
              "      <td>-0.046250</td>\n",
              "      <td>-0.008567</td>\n",
              "      <td>-0.018495</td>\n",
              "      <td>-0.005773</td>\n",
              "      <td>-0.010654</td>\n",
              "      <td>-0.050474</td>\n",
              "      <td>-0.047832</td>\n",
              "      <td>-0.039709</td>\n",
              "      <td>0.001393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type31</th>\n",
              "      <td>0.025826</td>\n",
              "      <td>0.094913</td>\n",
              "      <td>-0.001893</td>\n",
              "      <td>-0.077402</td>\n",
              "      <td>0.050385</td>\n",
              "      <td>0.010568</td>\n",
              "      <td>0.067611</td>\n",
              "      <td>-0.042192</td>\n",
              "      <td>0.038758</td>\n",
              "      <td>0.052327</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.032765</td>\n",
              "      <td>-0.030879</td>\n",
              "      <td>-0.005720</td>\n",
              "      <td>-0.012348</td>\n",
              "      <td>-0.003855</td>\n",
              "      <td>-0.007113</td>\n",
              "      <td>-0.033699</td>\n",
              "      <td>-0.031935</td>\n",
              "      <td>-0.026512</td>\n",
              "      <td>-0.079882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type32</th>\n",
              "      <td>0.068048</td>\n",
              "      <td>0.177010</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>-0.152895</td>\n",
              "      <td>0.152044</td>\n",
              "      <td>0.041557</td>\n",
              "      <td>0.073202</td>\n",
              "      <td>-0.013400</td>\n",
              "      <td>0.096333</td>\n",
              "      <td>0.059921</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.045065</td>\n",
              "      <td>-0.008347</td>\n",
              "      <td>-0.018021</td>\n",
              "      <td>-0.005625</td>\n",
              "      <td>-0.010381</td>\n",
              "      <td>-0.049181</td>\n",
              "      <td>-0.046606</td>\n",
              "      <td>-0.038692</td>\n",
              "      <td>-0.132312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type33</th>\n",
              "      <td>0.066887</td>\n",
              "      <td>0.127712</td>\n",
              "      <td>0.018728</td>\n",
              "      <td>0.085263</td>\n",
              "      <td>0.070031</td>\n",
              "      <td>0.080899</td>\n",
              "      <td>0.074930</td>\n",
              "      <td>-0.034492</td>\n",
              "      <td>-0.014229</td>\n",
              "      <td>0.016483</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.045065</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.007867</td>\n",
              "      <td>-0.016984</td>\n",
              "      <td>-0.005302</td>\n",
              "      <td>-0.009784</td>\n",
              "      <td>-0.046350</td>\n",
              "      <td>-0.043924</td>\n",
              "      <td>-0.036465</td>\n",
              "      <td>-0.078955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type34</th>\n",
              "      <td>0.022520</td>\n",
              "      <td>0.023214</td>\n",
              "      <td>0.016168</td>\n",
              "      <td>-0.032372</td>\n",
              "      <td>0.045031</td>\n",
              "      <td>0.022227</td>\n",
              "      <td>0.028308</td>\n",
              "      <td>-0.003051</td>\n",
              "      <td>0.038619</td>\n",
              "      <td>0.021390</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.008347</td>\n",
              "      <td>-0.007867</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.003146</td>\n",
              "      <td>-0.000982</td>\n",
              "      <td>-0.001812</td>\n",
              "      <td>-0.008585</td>\n",
              "      <td>-0.008136</td>\n",
              "      <td>-0.006754</td>\n",
              "      <td>-0.003470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type35</th>\n",
              "      <td>0.057480</td>\n",
              "      <td>0.119577</td>\n",
              "      <td>0.002710</td>\n",
              "      <td>-0.050070</td>\n",
              "      <td>-0.033122</td>\n",
              "      <td>-0.046257</td>\n",
              "      <td>0.081723</td>\n",
              "      <td>0.027107</td>\n",
              "      <td>0.035543</td>\n",
              "      <td>-0.002470</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018021</td>\n",
              "      <td>-0.016984</td>\n",
              "      <td>-0.003146</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.002120</td>\n",
              "      <td>-0.003912</td>\n",
              "      <td>-0.018535</td>\n",
              "      <td>-0.017565</td>\n",
              "      <td>-0.014582</td>\n",
              "      <td>0.114327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type36</th>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.040554</td>\n",
              "      <td>0.010398</td>\n",
              "      <td>-0.001527</td>\n",
              "      <td>0.042023</td>\n",
              "      <td>0.025059</td>\n",
              "      <td>0.032179</td>\n",
              "      <td>0.013432</td>\n",
              "      <td>0.034402</td>\n",
              "      <td>0.004303</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.005625</td>\n",
              "      <td>-0.005302</td>\n",
              "      <td>-0.000982</td>\n",
              "      <td>-0.002120</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.001221</td>\n",
              "      <td>-0.005786</td>\n",
              "      <td>-0.005483</td>\n",
              "      <td>-0.004552</td>\n",
              "      <td>0.025726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type37</th>\n",
              "      <td>0.016040</td>\n",
              "      <td>0.073433</td>\n",
              "      <td>-0.051523</td>\n",
              "      <td>0.004761</td>\n",
              "      <td>-0.017976</td>\n",
              "      <td>-0.028168</td>\n",
              "      <td>0.062208</td>\n",
              "      <td>0.006541</td>\n",
              "      <td>-0.037890</td>\n",
              "      <td>-0.030732</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.010381</td>\n",
              "      <td>-0.009784</td>\n",
              "      <td>-0.001812</td>\n",
              "      <td>-0.003912</td>\n",
              "      <td>-0.001221</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.010677</td>\n",
              "      <td>-0.010118</td>\n",
              "      <td>-0.008400</td>\n",
              "      <td>0.071210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type38</th>\n",
              "      <td>0.086932</td>\n",
              "      <td>0.321949</td>\n",
              "      <td>0.043918</td>\n",
              "      <td>-0.154715</td>\n",
              "      <td>0.081793</td>\n",
              "      <td>-0.018610</td>\n",
              "      <td>0.205165</td>\n",
              "      <td>-0.016841</td>\n",
              "      <td>0.103441</td>\n",
              "      <td>0.071472</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.049181</td>\n",
              "      <td>-0.046350</td>\n",
              "      <td>-0.008585</td>\n",
              "      <td>-0.018535</td>\n",
              "      <td>-0.005786</td>\n",
              "      <td>-0.010677</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.047936</td>\n",
              "      <td>-0.039795</td>\n",
              "      <td>0.257810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type39</th>\n",
              "      <td>0.083376</td>\n",
              "      <td>0.294134</td>\n",
              "      <td>-0.032364</td>\n",
              "      <td>0.056108</td>\n",
              "      <td>0.076257</td>\n",
              "      <td>0.061113</td>\n",
              "      <td>0.161078</td>\n",
              "      <td>0.034610</td>\n",
              "      <td>-0.072378</td>\n",
              "      <td>-0.062608</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.046606</td>\n",
              "      <td>-0.043924</td>\n",
              "      <td>-0.008136</td>\n",
              "      <td>-0.017565</td>\n",
              "      <td>-0.005483</td>\n",
              "      <td>-0.010118</td>\n",
              "      <td>-0.047936</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.037712</td>\n",
              "      <td>0.240384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Soil_Type40</th>\n",
              "      <td>0.122475</td>\n",
              "      <td>0.281407</td>\n",
              "      <td>-0.006624</td>\n",
              "      <td>-0.039752</td>\n",
              "      <td>0.183069</td>\n",
              "      <td>0.153158</td>\n",
              "      <td>0.142089</td>\n",
              "      <td>-0.038669</td>\n",
              "      <td>-0.026886</td>\n",
              "      <td>0.025373</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.038692</td>\n",
              "      <td>-0.036465</td>\n",
              "      <td>-0.006754</td>\n",
              "      <td>-0.014582</td>\n",
              "      <td>-0.004552</td>\n",
              "      <td>-0.008400</td>\n",
              "      <td>-0.039795</td>\n",
              "      <td>-0.037712</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.205851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cover_Type</th>\n",
              "      <td>0.108363</td>\n",
              "      <td>0.004112</td>\n",
              "      <td>0.003701</td>\n",
              "      <td>0.095533</td>\n",
              "      <td>-0.050755</td>\n",
              "      <td>0.049991</td>\n",
              "      <td>-0.064658</td>\n",
              "      <td>-0.003138</td>\n",
              "      <td>-0.099153</td>\n",
              "      <td>-0.044096</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.132312</td>\n",
              "      <td>-0.078955</td>\n",
              "      <td>-0.003470</td>\n",
              "      <td>0.114327</td>\n",
              "      <td>0.025726</td>\n",
              "      <td>0.071210</td>\n",
              "      <td>0.257810</td>\n",
              "      <td>0.240384</td>\n",
              "      <td>0.205851</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>56 rows × 56 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f3fcdaf-0d0c-4f13-bdb6-b4ae5fd1eaa2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f3fcdaf-0d0c-4f13-bdb6-b4ae5fd1eaa2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f3fcdaf-0d0c-4f13-bdb6-b4ae5fd1eaa2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_forestcover['Soil_Type15'] = df_forestcover['Soil_Type15'].replace(np.nan, 0)"
      ],
      "metadata": {
        "id": "SeF81YzU1CJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,roc_auc_score"
      ],
      "metadata": {
        "id": "mxsLwF1atFYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = df_forestcover.drop(['Cover_Type'], axis=1)\n",
        "y = df_forestcover['Cover_Type']"
      ],
      "metadata": {
        "id": "Ih7QCKnZsNpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=12)"
      ],
      "metadata": {
        "id": "t47kB38sspmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRf_6EsgMXbf",
        "outputId": "b5484f08-5d53-406a-aa01-a213d3966b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11340, 55)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXbjWaQOMyaI",
        "outputId": "c49d2b45-dfa8-45bc-d6fc-e39f3170dbc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11340,)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qiu3bXYqD2wc",
        "outputId": "72672e67-2fc3-44d4-fe43-e96f6c9a6dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3780, 55)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPaR6u2VD9r1",
        "outputId": "ad1f16d6-11ee-4b41-bcb8-24011d0a7d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3780,)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VC8w_pJtQ7U",
        "outputId": "1e338d2d-4746-4493-9c21-787594b6b093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    1659\n",
              "7    1637\n",
              "2    1624\n",
              "1    1614\n",
              "3    1606\n",
              "4    1604\n",
              "6    1596\n",
              "Name: Cover_Type, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train and test the knn classifier \n",
        "clf=KNeighborsClassifier(n_neighbors=5)"
      ],
      "metadata": {
        "id": "aNFax07FtcGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(x_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr9XCZf-tjNe",
        "outputId": "51357d3e-d3a4-431d-ca39-96001babcc41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=clf.predict(x_test)"
      ],
      "metadata": {
        "id": "leLA89Xhtqzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_pred,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xURbPz-Vt0pQ",
        "outputId": "b59188ba-7eda-4e21-e6c2-f9be588938be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.68      0.75      0.71       495\n",
            "           2       0.58      0.74      0.65       420\n",
            "           3       0.73      0.78      0.75       521\n",
            "           4       0.92      0.85      0.88       607\n",
            "           5       0.96      0.83      0.89       580\n",
            "           6       0.82      0.82      0.82       566\n",
            "           7       0.97      0.86      0.91       591\n",
            "\n",
            "    accuracy                           0.81      3780\n",
            "   macro avg       0.81      0.80      0.80      3780\n",
            "weighted avg       0.82      0.81      0.81      3780\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn. tree import DecisionTreeClassifier\n",
        "model=DecisionTreeClassifier()\n",
        "model.fit(x_train,y_train)\n",
        "print(\"Results of DecisionTreeClassifier: \\n\")\n",
        "print(classification_report(model.predict(x_test),y_test))\n",
        "print(\"-------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzrxtfHbwWiz",
        "outputId": "57b7efcf-2fa3-4e00-e740-4a651f4f501c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results of DecisionTreeClassifier: \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.68      0.65      0.66       564\n",
            "           2       0.59      0.62      0.60       512\n",
            "           3       0.75      0.78      0.76       529\n",
            "           4       0.92      0.92      0.92       555\n",
            "           5       0.86      0.84      0.85       513\n",
            "           6       0.81      0.78      0.80       584\n",
            "           7       0.90      0.90      0.90       523\n",
            "\n",
            "    accuracy                           0.79      3780\n",
            "   macro avg       0.79      0.79      0.79      3780\n",
            "weighted avg       0.79      0.79      0.79      3780\n",
            "\n",
            "-------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf=RandomForestClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "y_pred=clf.predict(x_test)\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge_0G5pXxdcG",
        "outputId": "c230e041-8378-4c3f-d6d3-160f39dfdc87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.77      0.78      0.78       546\n",
            "           2       0.79      0.67      0.72       536\n",
            "           3       0.86      0.84      0.85       554\n",
            "           4       0.93      0.98      0.95       556\n",
            "           5       0.91      0.97      0.94       501\n",
            "           6       0.87      0.88      0.88       564\n",
            "           7       0.93      0.97      0.95       523\n",
            "\n",
            "    accuracy                           0.87      3780\n",
            "   macro avg       0.87      0.87      0.87      3780\n",
            "weighted avg       0.87      0.87      0.87      3780\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train=clf.predict(x_train)"
      ],
      "metadata": {
        "id": "esve0TjS1yJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_pred_train,y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuhUFLtP2Ack",
        "outputId": "2942a0a8-5a0b-42da-cc25-980f411222ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00      1614\n",
            "           2       1.00      1.00      1.00      1624\n",
            "           3       1.00      1.00      1.00      1606\n",
            "           4       1.00      1.00      1.00      1604\n",
            "           5       1.00      1.00      1.00      1659\n",
            "           6       1.00      1.00      1.00      1596\n",
            "           7       1.00      1.00      1.00      1637\n",
            "\n",
            "    accuracy                           1.00     11340\n",
            "   macro avg       1.00      1.00      1.00     11340\n",
            "weighted avg       1.00      1.00      1.00     11340\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "TvXXpFqQ3YJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ANN = Sequential()"
      ],
      "metadata": {
        "id": "qkgyP4hZ356X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ANN.add(Dense(units=55, activation='relu'))\n",
        "ANN.add(Dense(units=10,activation='softmax'))"
      ],
      "metadata": {
        "id": "NVusn6Z53i8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "#name of the file\n",
        "filepath = 'bestmodel.h5'\n",
        "#monitor=val_loss for decrease\n",
        "mc = ModelCheckpoint(filepath, monitor='val_loss', mode='min', verbose=1)"
      ],
      "metadata": {
        "id": "AXu16FsvOKOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "38jr64HKCHg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "4GcVundaFLrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain = to_categorical(y_train, 10)"
      ],
      "metadata": {
        "id": "jV3gzo6aHzWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytest = to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "nemHtqx7IB6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ANN.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "qnMdqAtPBouQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "mc = ModelCheckpoint(filepath='bestmodel.h5', monitor='accuracy', mode='max', verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "DlDXBfBDLqKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = ANN.fit(x_train, y_train, epochs=10, validation_split=0.25, callbacks=[mc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwDVP4SjOX6e",
        "outputId": "5a68b734-d87a-4c01-d9fe-f3e29c5d9ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "255/266 [===========================>..] - ETA: 0s - loss: 2.0127 - accuracy: 0.1945\n",
            "Epoch 1: accuracy improved from -inf to 0.19318, saving model to bestmodel.h5\n",
            "266/266 [==============================] - 1s 4ms/step - loss: 2.0070 - accuracy: 0.1932 - val_loss: 1.8700 - val_accuracy: 0.2148\n",
            "Epoch 2/10\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9058 - accuracy: 0.1966\n",
            "Epoch 2: accuracy improved from 0.19318 to 0.19506, saving model to bestmodel.h5\n",
            "266/266 [==============================] - 1s 3ms/step - loss: 1.9074 - accuracy: 0.1951 - val_loss: 1.9598 - val_accuracy: 0.1443\n",
            "Epoch 3/10\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9520 - accuracy: 0.1412\n",
            "Epoch 3: accuracy did not improve from 0.19506\n",
            "266/266 [==============================] - 1s 3ms/step - loss: 1.9520 - accuracy: 0.1406 - val_loss: 1.9490 - val_accuracy: 0.1418\n",
            "Epoch 4/10\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9502 - accuracy: 0.1413\n",
            "Epoch 4: accuracy did not improve from 0.19506\n",
            "266/266 [==============================] - 1s 3ms/step - loss: 1.9502 - accuracy: 0.1411 - val_loss: 1.9473 - val_accuracy: 0.1496\n",
            "Epoch 5/10\n",
            "244/266 [==========================>...] - ETA: 0s - loss: 1.9491 - accuracy: 0.1404\n",
            "Epoch 5: accuracy did not improve from 0.19506\n",
            "266/266 [==============================] - 1s 3ms/step - loss: 1.9491 - accuracy: 0.1398 - val_loss: 1.9489 - val_accuracy: 0.1397\n",
            "Epoch 6/10\n",
            "246/266 [==========================>...] - ETA: 0s - loss: 1.9493 - accuracy: 0.1433\n",
            "Epoch 6: accuracy did not improve from 0.19506\n",
            "266/266 [==============================] - 1s 3ms/step - loss: 1.9493 - accuracy: 0.1427 - val_loss: 1.9475 - val_accuracy: 0.1418\n",
            "Epoch 7/10\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9490 - accuracy: 0.1369\n",
            "Epoch 7: accuracy did not improve from 0.19506\n",
            "266/266 [==============================] - 1s 3ms/step - loss: 1.9490 - accuracy: 0.1365 - val_loss: 1.9471 - val_accuracy: 0.1436\n",
            "Epoch 8/10\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9484 - accuracy: 0.1389\n",
            "Epoch 8: accuracy did not improve from 0.19506\n",
            "266/266 [==============================] - 1s 3ms/step - loss: 1.9484 - accuracy: 0.1387 - val_loss: 1.9485 - val_accuracy: 0.1496\n",
            "Epoch 9/10\n",
            "248/266 [==========================>...] - ETA: 0s - loss: 1.9487 - accuracy: 0.1373\n",
            "Epoch 9: accuracy did not improve from 0.19506\n",
            "266/266 [==============================] - 1s 3ms/step - loss: 1.9487 - accuracy: 0.1372 - val_loss: 1.9477 - val_accuracy: 0.1397\n",
            "Epoch 10/10\n",
            "257/266 [===========================>..] - ETA: 0s - loss: 1.9481 - accuracy: 0.1391\n",
            "Epoch 10: accuracy did not improve from 0.19506\n",
            "266/266 [==============================] - 1s 3ms/step - loss: 1.9479 - accuracy: 0.1400 - val_loss: 1.9514 - val_accuracy: 0.1397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model"
      ],
      "metadata": {
        "id": "lkPAQcIfOzfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bestmodel = load_model('bestmodel.h5')"
      ],
      "metadata": {
        "id": "YpijkrwtO3UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bestmodel.summary()"
      ],
      "metadata": {
        "id": "bj0WBwYYPmLn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "688ffac3-4627-4173-8309-34880f0a0434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 55)                3080      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7)                 392       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 55)                440       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                560       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,472\n",
            "Trainable params: 4,472\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bestmodel.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "mb-u4Y7SO-jL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e9c2893-08ec-4b2d-a6c4-57925108b8c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "119/119 [==============================] - 0s 2ms/step - loss: 1.9632 - accuracy: 0.1418\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.9631983041763306, 0.1417989432811737]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Avoidable bias or variance\n",
        "\n",
        "\n",
        "# Avoidable Bias is more.\n"
      ],
      "metadata": {
        "id": "0jSYyPRA244j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SecondANN = Sequential()"
      ],
      "metadata": {
        "id": "TNUVS5p0Xlu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SecondANN.add(Dense(units=256, input_dim=55))\n",
        "SecondANN.add(Dense(units=256, activation='relu'))\n",
        "SecondANN.add(Dense(units=64,activation='relu'))\n",
        "\n",
        "#final layer\n",
        "SecondANN.add(Dense(units=10, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "zJWL3skuX01y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "#name of the file\n",
        "filepath = 'bestmodel.h5'\n",
        "#monitor=val_loss for decrease\n",
        "mc = ModelCheckpoint(filepath, monitor='val_loss', mode='min', verbose=1)"
      ],
      "metadata": {
        "id": "fgBbmK95X01z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SecondANN.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ydUuRnZ3X010"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = SecondANN.fit(x_train, y_train, epochs=1000, validation_split=0.25, callbacks=[mc])"
      ],
      "metadata": {
        "id": "uF5jNyJdX010",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1307e0d-c378-429e-bafa-c744deff14db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 2.2498 - accuracy: 0.1394\n",
            "Epoch 1: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 7ms/step - loss: 2.2486 - accuracy: 0.1387 - val_loss: 2.2015 - val_accuracy: 0.1407\n",
            "Epoch 2/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 2.1672 - accuracy: 0.1447\n",
            "Epoch 2: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 2.1668 - accuracy: 0.1446 - val_loss: 2.1364 - val_accuracy: 0.1397\n",
            "Epoch 3/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 2.1135 - accuracy: 0.1377\n",
            "Epoch 3: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 2.1134 - accuracy: 0.1377 - val_loss: 2.0929 - val_accuracy: 0.1397\n",
            "Epoch 4/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 2.0772 - accuracy: 0.1408\n",
            "Epoch 4: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 2.0770 - accuracy: 0.1419 - val_loss: 2.0627 - val_accuracy: 0.1397\n",
            "Epoch 5/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 2.0513 - accuracy: 0.1454\n",
            "Epoch 5: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 2.0511 - accuracy: 0.1459 - val_loss: 2.0407 - val_accuracy: 0.1397\n",
            "Epoch 6/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 2.0323 - accuracy: 0.1434\n",
            "Epoch 6: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 2.0322 - accuracy: 0.1442 - val_loss: 2.0242 - val_accuracy: 0.1397\n",
            "Epoch 7/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 2.0179 - accuracy: 0.1463\n",
            "Epoch 7: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 2.0177 - accuracy: 0.1459 - val_loss: 2.0116 - val_accuracy: 0.1397\n",
            "Epoch 8/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 2.0066 - accuracy: 0.1391\n",
            "Epoch 8: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 1s 6ms/step - loss: 2.0065 - accuracy: 0.1396 - val_loss: 2.0016 - val_accuracy: 0.1397\n",
            "Epoch 9/1000\n",
            "257/266 [===========================>..] - ETA: 0s - loss: 1.9976 - accuracy: 0.1469\n",
            "Epoch 9: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9975 - accuracy: 0.1459 - val_loss: 1.9936 - val_accuracy: 0.1397\n",
            "Epoch 10/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9903 - accuracy: 0.1459\n",
            "Epoch 10: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9903 - accuracy: 0.1459 - val_loss: 1.9870 - val_accuracy: 0.1397\n",
            "Epoch 11/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9843 - accuracy: 0.1456\n",
            "Epoch 11: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9843 - accuracy: 0.1449 - val_loss: 1.9816 - val_accuracy: 0.1397\n",
            "Epoch 12/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9794 - accuracy: 0.1454\n",
            "Epoch 12: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9793 - accuracy: 0.1459 - val_loss: 1.9771 - val_accuracy: 0.1397\n",
            "Epoch 13/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9751 - accuracy: 0.1440\n",
            "Epoch 13: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9751 - accuracy: 0.1439 - val_loss: 1.9732 - val_accuracy: 0.1397\n",
            "Epoch 14/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9716 - accuracy: 0.1430\n",
            "Epoch 14: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9716 - accuracy: 0.1429 - val_loss: 1.9700 - val_accuracy: 0.1397\n",
            "Epoch 15/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9686 - accuracy: 0.1456\n",
            "Epoch 15: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9686 - accuracy: 0.1459 - val_loss: 1.9671 - val_accuracy: 0.1397\n",
            "Epoch 16/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9660 - accuracy: 0.1412\n",
            "Epoch 16: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9660 - accuracy: 0.1410 - val_loss: 1.9647 - val_accuracy: 0.1397\n",
            "Epoch 17/1000\n",
            "257/266 [===========================>..] - ETA: 0s - loss: 1.9637 - accuracy: 0.1415\n",
            "Epoch 17: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9637 - accuracy: 0.1420 - val_loss: 1.9626 - val_accuracy: 0.1397\n",
            "Epoch 18/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9617 - accuracy: 0.1459\n",
            "Epoch 18: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9617 - accuracy: 0.1459 - val_loss: 1.9607 - val_accuracy: 0.1397\n",
            "Epoch 19/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9599 - accuracy: 0.1406\n",
            "Epoch 19: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9599 - accuracy: 0.1406 - val_loss: 1.9590 - val_accuracy: 0.1496\n",
            "Epoch 20/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9584 - accuracy: 0.1420\n",
            "Epoch 20: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9584 - accuracy: 0.1425 - val_loss: 1.9576 - val_accuracy: 0.1397\n",
            "Epoch 21/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9571 - accuracy: 0.1426\n",
            "Epoch 21: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9571 - accuracy: 0.1426 - val_loss: 1.9564 - val_accuracy: 0.1397\n",
            "Epoch 22/1000\n",
            "257/266 [===========================>..] - ETA: 0s - loss: 1.9559 - accuracy: 0.1423\n",
            "Epoch 22: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9559 - accuracy: 0.1424 - val_loss: 1.9552 - val_accuracy: 0.1397\n",
            "Epoch 23/1000\n",
            "257/266 [===========================>..] - ETA: 0s - loss: 1.9549 - accuracy: 0.1413\n",
            "Epoch 23: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9548 - accuracy: 0.1425 - val_loss: 1.9543 - val_accuracy: 0.1397\n",
            "Epoch 24/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9539 - accuracy: 0.1439\n",
            "Epoch 24: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9539 - accuracy: 0.1433 - val_loss: 1.9534 - val_accuracy: 0.1397\n",
            "Epoch 25/1000\n",
            "256/266 [===========================>..] - ETA: 0s - loss: 1.9530 - accuracy: 0.1440\n",
            "Epoch 25: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9530 - accuracy: 0.1434 - val_loss: 1.9526 - val_accuracy: 0.1397\n",
            "Epoch 26/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9523 - accuracy: 0.1463\n",
            "Epoch 26: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9523 - accuracy: 0.1459 - val_loss: 1.9519 - val_accuracy: 0.1397\n",
            "Epoch 27/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9516 - accuracy: 0.1430\n",
            "Epoch 27: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9516 - accuracy: 0.1425 - val_loss: 1.9513 - val_accuracy: 0.1397\n",
            "Epoch 28/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9510 - accuracy: 0.1425\n",
            "Epoch 28: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9510 - accuracy: 0.1425 - val_loss: 1.9507 - val_accuracy: 0.1397\n",
            "Epoch 29/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9504 - accuracy: 0.1473\n",
            "Epoch 29: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9505 - accuracy: 0.1459 - val_loss: 1.9502 - val_accuracy: 0.1397\n",
            "Epoch 30/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9500 - accuracy: 0.1463\n",
            "Epoch 30: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9501 - accuracy: 0.1458 - val_loss: 1.9497 - val_accuracy: 0.1496\n",
            "Epoch 31/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9496 - accuracy: 0.1430\n",
            "Epoch 31: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9496 - accuracy: 0.1426 - val_loss: 1.9493 - val_accuracy: 0.1397\n",
            "Epoch 32/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9492 - accuracy: 0.1460\n",
            "Epoch 32: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9492 - accuracy: 0.1452 - val_loss: 1.9490 - val_accuracy: 0.1397\n",
            "Epoch 33/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9489 - accuracy: 0.1462\n",
            "Epoch 33: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9489 - accuracy: 0.1459 - val_loss: 1.9487 - val_accuracy: 0.1397\n",
            "Epoch 34/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9486 - accuracy: 0.1440\n",
            "Epoch 34: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9486 - accuracy: 0.1440 - val_loss: 1.9484 - val_accuracy: 0.1397\n",
            "Epoch 35/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9483 - accuracy: 0.1436\n",
            "Epoch 35: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9483 - accuracy: 0.1440 - val_loss: 1.9482 - val_accuracy: 0.1397\n",
            "Epoch 36/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9481 - accuracy: 0.1461\n",
            "Epoch 36: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9481 - accuracy: 0.1459 - val_loss: 1.9479 - val_accuracy: 0.1397\n",
            "Epoch 37/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9479 - accuracy: 0.1458\n",
            "Epoch 37: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9479 - accuracy: 0.1459 - val_loss: 1.9477 - val_accuracy: 0.1397\n",
            "Epoch 38/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9477 - accuracy: 0.1438\n",
            "Epoch 38: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9477 - accuracy: 0.1440 - val_loss: 1.9475 - val_accuracy: 0.1397\n",
            "Epoch 39/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9475 - accuracy: 0.1448\n",
            "Epoch 39: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9475 - accuracy: 0.1447 - val_loss: 1.9474 - val_accuracy: 0.1397\n",
            "Epoch 40/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9473 - accuracy: 0.1445\n",
            "Epoch 40: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9473 - accuracy: 0.1440 - val_loss: 1.9472 - val_accuracy: 0.1397\n",
            "Epoch 41/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9472 - accuracy: 0.1464\n",
            "Epoch 41: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9472 - accuracy: 0.1459 - val_loss: 1.9471 - val_accuracy: 0.1397\n",
            "Epoch 42/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9471 - accuracy: 0.1439\n",
            "Epoch 42: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9471 - accuracy: 0.1438 - val_loss: 1.9470 - val_accuracy: 0.1397\n",
            "Epoch 43/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9470 - accuracy: 0.1365\n",
            "Epoch 43: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9470 - accuracy: 0.1373 - val_loss: 1.9469 - val_accuracy: 0.1397\n",
            "Epoch 44/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9469 - accuracy: 0.1425\n",
            "Epoch 44: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9469 - accuracy: 0.1425 - val_loss: 1.9468 - val_accuracy: 0.1397\n",
            "Epoch 45/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9468 - accuracy: 0.1459\n",
            "Epoch 45: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9467 - accuracy: 0.1459 - val_loss: 1.9467 - val_accuracy: 0.1397\n",
            "Epoch 46/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9467 - accuracy: 0.1455\n",
            "Epoch 46: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9467 - accuracy: 0.1458 - val_loss: 1.9466 - val_accuracy: 0.1397\n",
            "Epoch 47/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9467 - accuracy: 0.1439\n",
            "Epoch 47: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9467 - accuracy: 0.1440 - val_loss: 1.9466 - val_accuracy: 0.1397\n",
            "Epoch 48/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9466 - accuracy: 0.1442\n",
            "Epoch 48: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9466 - accuracy: 0.1444 - val_loss: 1.9465 - val_accuracy: 0.1397\n",
            "Epoch 49/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9466 - accuracy: 0.1410\n",
            "Epoch 49: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9466 - accuracy: 0.1425 - val_loss: 1.9464 - val_accuracy: 0.1397\n",
            "Epoch 50/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9464 - accuracy: 0.1398\n",
            "Epoch 50: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9464 - accuracy: 0.1407 - val_loss: 1.9464 - val_accuracy: 0.1397\n",
            "Epoch 51/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9464 - accuracy: 0.1459\n",
            "Epoch 51: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9464 - accuracy: 0.1459 - val_loss: 1.9464 - val_accuracy: 0.1397\n",
            "Epoch 52/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9463 - accuracy: 0.1443\n",
            "Epoch 52: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9464 - accuracy: 0.1446 - val_loss: 1.9463 - val_accuracy: 0.1397\n",
            "Epoch 53/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9463 - accuracy: 0.1418\n",
            "Epoch 53: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9463 - accuracy: 0.1425 - val_loss: 1.9462 - val_accuracy: 0.1397\n",
            "Epoch 54/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9462 - accuracy: 0.1399\n",
            "Epoch 54: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9463 - accuracy: 0.1399 - val_loss: 1.9463 - val_accuracy: 0.1397\n",
            "Epoch 55/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9463 - accuracy: 0.1437\n",
            "Epoch 55: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9463 - accuracy: 0.1444 - val_loss: 1.9462 - val_accuracy: 0.1397\n",
            "Epoch 56/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9462 - accuracy: 0.1441\n",
            "Epoch 56: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9462 - accuracy: 0.1440 - val_loss: 1.9462 - val_accuracy: 0.1397\n",
            "Epoch 57/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9462 - accuracy: 0.1421\n",
            "Epoch 57: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9462 - accuracy: 0.1416 - val_loss: 1.9462 - val_accuracy: 0.1397\n",
            "Epoch 58/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1446\n",
            "Epoch 58: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9462 - accuracy: 0.1438 - val_loss: 1.9462 - val_accuracy: 0.1397\n",
            "Epoch 59/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9462 - accuracy: 0.1463\n",
            "Epoch 59: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9462 - accuracy: 0.1459 - val_loss: 1.9461 - val_accuracy: 0.1397\n",
            "Epoch 60/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1436\n",
            "Epoch 60: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9461 - accuracy: 0.1438 - val_loss: 1.9461 - val_accuracy: 0.1397\n",
            "Epoch 61/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1460\n",
            "Epoch 61: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9461 - accuracy: 0.1459 - val_loss: 1.9461 - val_accuracy: 0.1397\n",
            "Epoch 62/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1450\n",
            "Epoch 62: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9461 - accuracy: 0.1445 - val_loss: 1.9460 - val_accuracy: 0.1496\n",
            "Epoch 63/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1378\n",
            "Epoch 63: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 12ms/step - loss: 1.9461 - accuracy: 0.1380 - val_loss: 1.9461 - val_accuracy: 0.1397\n",
            "Epoch 64/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1447\n",
            "Epoch 64: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9461 - accuracy: 0.1439 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 65/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1450\n",
            "Epoch 65: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9461 - accuracy: 0.1446 - val_loss: 1.9461 - val_accuracy: 0.1397\n",
            "Epoch 66/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1408\n",
            "Epoch 66: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9461 - accuracy: 0.1411 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 67/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1434\n",
            "Epoch 67: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9461 - accuracy: 0.1434 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 68/1000\n",
            "257/266 [===========================>..] - ETA: 0s - loss: 1.9461 - accuracy: 0.1395\n",
            "Epoch 68: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1393 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 69/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1389\n",
            "Epoch 69: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9461 - accuracy: 0.1382 - val_loss: 1.9460 - val_accuracy: 0.1496\n",
            "Epoch 70/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1419\n",
            "Epoch 70: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 9ms/step - loss: 1.9461 - accuracy: 0.1417 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 71/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1406\n",
            "Epoch 71: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1402 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 72/1000\n",
            "256/266 [===========================>..] - ETA: 0s - loss: 1.9460 - accuracy: 0.1440\n",
            "Epoch 72: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9461 - accuracy: 0.1436 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 73/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1424\n",
            "Epoch 73: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1411 - val_loss: 1.9460 - val_accuracy: 0.1496\n",
            "Epoch 74/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1420\n",
            "Epoch 74: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1416 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 75/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1423\n",
            "Epoch 75: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1432 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 76/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1427\n",
            "Epoch 76: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1433 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 77/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1461\n",
            "Epoch 77: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9461 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 78/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1406\n",
            "Epoch 78: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9461 - accuracy: 0.1403 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 79/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1461\n",
            "Epoch 79: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 80/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 80: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1437 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 81/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1388\n",
            "Epoch 81: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1389 - val_loss: 1.9460 - val_accuracy: 0.1496\n",
            "Epoch 82/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1432\n",
            "Epoch 82: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1432 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 83/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1447\n",
            "Epoch 83: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1443 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 84/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1362\n",
            "Epoch 84: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1367 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 85/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1461\n",
            "Epoch 85: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 86/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1443\n",
            "Epoch 86: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1433 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 87/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1452\n",
            "Epoch 87: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 88/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1407\n",
            "Epoch 88: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1416 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 89/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1458\n",
            "Epoch 89: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 90/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9459 - accuracy: 0.1461\n",
            "Epoch 90: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 91/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1422\n",
            "Epoch 91: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1422 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 92/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1455\n",
            "Epoch 92: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1457 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 93/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1440\n",
            "Epoch 93: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 94/1000\n",
            "257/266 [===========================>..] - ETA: 0s - loss: 1.9459 - accuracy: 0.1443\n",
            "Epoch 94: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1438 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 95/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 95: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 96/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1456\n",
            "Epoch 96: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1453 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 97/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1426\n",
            "Epoch 97: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1429 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 98/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1416\n",
            "Epoch 98: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1419 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 99/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1448\n",
            "Epoch 99: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1445 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 100/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1419\n",
            "Epoch 100: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1420 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 101/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1426\n",
            "Epoch 101: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1424 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 102/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1446\n",
            "Epoch 102: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1439 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 103/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1418\n",
            "Epoch 103: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1422 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 104/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 104: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 105/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1432\n",
            "Epoch 105: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1442 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 106/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1457\n",
            "Epoch 106: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 107/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1383\n",
            "Epoch 107: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1386 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 108/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1446\n",
            "Epoch 108: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1447 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 109/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1414\n",
            "Epoch 109: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1414 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 110/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1464\n",
            "Epoch 110: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 111/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1428\n",
            "Epoch 111: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1425 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 112/1000\n",
            "257/266 [===========================>..] - ETA: 0s - loss: 1.9460 - accuracy: 0.1443\n",
            "Epoch 112: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9460 - val_accuracy: 0.1496\n",
            "Epoch 113/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1391\n",
            "Epoch 113: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1398 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 114/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1455\n",
            "Epoch 114: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1454 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 115/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1457\n",
            "Epoch 115: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1453 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 116/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1410\n",
            "Epoch 116: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1410 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 117/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1430\n",
            "Epoch 117: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1431 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 118/1000\n",
            "256/266 [===========================>..] - ETA: 0s - loss: 1.9460 - accuracy: 0.1404\n",
            "Epoch 118: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1410 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 119/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1442\n",
            "Epoch 119: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 120/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1427\n",
            "Epoch 120: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1432 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 121/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1462\n",
            "Epoch 121: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 122/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1434\n",
            "Epoch 122: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1434 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 123/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9459 - accuracy: 0.1457\n",
            "Epoch 123: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 124/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1458\n",
            "Epoch 124: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 125/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1394\n",
            "Epoch 125: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1392 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 126/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1404\n",
            "Epoch 126: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1414 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 127/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1458\n",
            "Epoch 127: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 128/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1448\n",
            "Epoch 128: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 129/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1410\n",
            "Epoch 129: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9461 - accuracy: 0.1412 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 130/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1397\n",
            "Epoch 130: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1397 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 131/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 131: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1432 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 132/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1430\n",
            "Epoch 132: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1429 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 133/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1442\n",
            "Epoch 133: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 134/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1436\n",
            "Epoch 134: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1434 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 135/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1414\n",
            "Epoch 135: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1414 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 136/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1454\n",
            "Epoch 136: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 137/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1443\n",
            "Epoch 137: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1443 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 138/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1412\n",
            "Epoch 138: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1407 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 139/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1454\n",
            "Epoch 139: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 140/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1431\n",
            "Epoch 140: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1442 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 141/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1433\n",
            "Epoch 141: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1434 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 142/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1434\n",
            "Epoch 142: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1432 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 143/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1454\n",
            "Epoch 143: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 144/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1394\n",
            "Epoch 144: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1398 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 145/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1458\n",
            "Epoch 145: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 146/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1463\n",
            "Epoch 146: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 147/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1452\n",
            "Epoch 147: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1453 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 148/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1416\n",
            "Epoch 148: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1419 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 149/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1429\n",
            "Epoch 149: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1430 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 150/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1462\n",
            "Epoch 150: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 151/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1378\n",
            "Epoch 151: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1387 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 152/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1365\n",
            "Epoch 152: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1363 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 153/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1450\n",
            "Epoch 153: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 154/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1462\n",
            "Epoch 154: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 155/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 155: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 156/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1447\n",
            "Epoch 156: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1453 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 157/1000\n",
            "257/266 [===========================>..] - ETA: 0s - loss: 1.9460 - accuracy: 0.1441\n",
            "Epoch 157: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1436 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 158/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1435\n",
            "Epoch 158: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1432 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 159/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1439\n",
            "Epoch 159: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1437 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 160/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1448\n",
            "Epoch 160: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 161/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1436\n",
            "Epoch 161: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1436 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 162/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1409\n",
            "Epoch 162: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1407 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 163/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1432\n",
            "Epoch 163: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1422 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 164/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9459 - accuracy: 0.1444\n",
            "Epoch 164: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 165/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1452\n",
            "Epoch 165: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 166/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1406\n",
            "Epoch 166: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1404 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 167/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1424\n",
            "Epoch 167: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1424 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 168/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1462\n",
            "Epoch 168: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 169/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1451\n",
            "Epoch 169: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1451 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 170/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1413\n",
            "Epoch 170: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1412 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 171/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1465\n",
            "Epoch 171: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 172/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1447\n",
            "Epoch 172: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 173/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1446\n",
            "Epoch 173: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1443 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 174/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1432\n",
            "Epoch 174: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1439 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 175/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1423\n",
            "Epoch 175: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1426 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 176/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1430\n",
            "Epoch 176: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1431 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 177/1000\n",
            "257/266 [===========================>..] - ETA: 0s - loss: 1.9460 - accuracy: 0.1465\n",
            "Epoch 177: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 178/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1418\n",
            "Epoch 178: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1418 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 179/1000\n",
            "256/266 [===========================>..] - ETA: 0s - loss: 1.9460 - accuracy: 0.1456\n",
            "Epoch 179: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 180/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1430\n",
            "Epoch 180: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1436 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 181/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1416\n",
            "Epoch 181: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1417 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 182/1000\n",
            "256/266 [===========================>..] - ETA: 0s - loss: 1.9460 - accuracy: 0.1473\n",
            "Epoch 182: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 183/1000\n",
            "257/266 [===========================>..] - ETA: 0s - loss: 1.9460 - accuracy: 0.1451\n",
            "Epoch 183: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1439 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 184/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1404\n",
            "Epoch 184: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1407 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 185/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1462\n",
            "Epoch 185: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 186/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1438\n",
            "Epoch 186: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1438 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 187/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 187: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 188/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1447\n",
            "Epoch 188: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1447 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 189/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1383\n",
            "Epoch 189: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1384 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 190/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1445\n",
            "Epoch 190: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1452 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 191/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1462\n",
            "Epoch 191: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 192/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1450\n",
            "Epoch 192: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 193/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1434\n",
            "Epoch 193: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1437 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 194/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1400\n",
            "Epoch 194: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1402 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 195/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1431\n",
            "Epoch 195: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1431 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 196/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1424\n",
            "Epoch 196: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1429 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 197/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1457\n",
            "Epoch 197: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 198/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 198: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 199/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1433\n",
            "Epoch 199: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1437 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 200/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1441\n",
            "Epoch 200: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1443 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 201/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1416\n",
            "Epoch 201: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1416 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 202/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1429\n",
            "Epoch 202: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1430 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 203/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1380\n",
            "Epoch 203: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1373 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 204/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1409\n",
            "Epoch 204: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1405 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 205/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1457\n",
            "Epoch 205: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 206/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 206: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1453 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 207/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1412\n",
            "Epoch 207: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1412 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 208/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1433\n",
            "Epoch 208: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1431 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 209/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1464\n",
            "Epoch 209: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 210/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1410\n",
            "Epoch 210: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1412 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 211/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 211: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1439 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 212/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1410\n",
            "Epoch 212: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1409 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 213/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1433\n",
            "Epoch 213: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1432 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 214/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1442\n",
            "Epoch 214: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1437 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 215/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1469\n",
            "Epoch 215: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 216/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 216: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1432 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 217/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1440\n",
            "Epoch 217: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9461 - accuracy: 0.1442 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 218/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1445\n",
            "Epoch 218: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1443 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 219/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 219: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 220/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1431\n",
            "Epoch 220: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1433 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 221/1000\n",
            "256/266 [===========================>..] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 221: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1445 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 222/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1452\n",
            "Epoch 222: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1449 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 223/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1453\n",
            "Epoch 223: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 224/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1419\n",
            "Epoch 224: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1419 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 225/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1439\n",
            "Epoch 225: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1442 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 226/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1431\n",
            "Epoch 226: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1431 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 227/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1462\n",
            "Epoch 227: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 228/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1421\n",
            "Epoch 228: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1416 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 229/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1373\n",
            "Epoch 229: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1370 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 230/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1440\n",
            "Epoch 230: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 231/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1444\n",
            "Epoch 231: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 232/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1456\n",
            "Epoch 232: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 233/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1468\n",
            "Epoch 233: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 234/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1422\n",
            "Epoch 234: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1425 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 235/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1464\n",
            "Epoch 235: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 236/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1434\n",
            "Epoch 236: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1429 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 237/1000\n",
            "256/266 [===========================>..] - ETA: 0s - loss: 1.9461 - accuracy: 0.1421\n",
            "Epoch 237: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1432 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 238/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1422\n",
            "Epoch 238: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1420 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 239/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1428\n",
            "Epoch 239: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1434 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 240/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1414\n",
            "Epoch 240: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1414 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 241/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1439\n",
            "Epoch 241: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1434 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 242/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9459 - accuracy: 0.1439\n",
            "Epoch 242: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1436 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 243/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1423\n",
            "Epoch 243: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1422 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 244/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1453\n",
            "Epoch 244: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 245/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1467\n",
            "Epoch 245: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 246/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1429\n",
            "Epoch 246: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1426 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 247/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1443\n",
            "Epoch 247: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1443 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 248/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1450\n",
            "Epoch 248: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 249/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1407\n",
            "Epoch 249: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1409 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 250/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1436\n",
            "Epoch 250: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1434 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 251/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1401\n",
            "Epoch 251: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1399 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 252/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1456\n",
            "Epoch 252: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1450 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 253/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1466\n",
            "Epoch 253: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1466 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 254/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1427\n",
            "Epoch 254: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1432 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 255/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 255: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 256/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1450\n",
            "Epoch 256: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1447 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 257/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1438\n",
            "Epoch 257: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1431 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 258/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1451\n",
            "Epoch 258: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1447 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 259/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1441\n",
            "Epoch 259: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1439 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 260/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1409\n",
            "Epoch 260: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1411 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 261/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1426\n",
            "Epoch 261: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1424 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 262/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1419\n",
            "Epoch 262: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1420 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 263/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1393\n",
            "Epoch 263: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1396 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 264/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 264: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 265/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1444\n",
            "Epoch 265: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1443 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 266/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1419\n",
            "Epoch 266: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1422 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 267/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1411\n",
            "Epoch 267: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1409 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 268/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1435\n",
            "Epoch 268: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9461 - accuracy: 0.1432 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 269/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1441\n",
            "Epoch 269: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1436 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 270/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1461\n",
            "Epoch 270: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1457 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 271/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1438\n",
            "Epoch 271: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 272/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1397\n",
            "Epoch 272: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1402 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 273/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1472\n",
            "Epoch 273: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 274/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1448\n",
            "Epoch 274: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1445 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 275/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 275: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 276/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1407\n",
            "Epoch 276: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1404 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 277/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1440\n",
            "Epoch 277: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1437 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 278/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1432\n",
            "Epoch 278: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1432 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 279/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1455\n",
            "Epoch 279: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1450 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 280/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1410\n",
            "Epoch 280: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1417 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 281/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1414\n",
            "Epoch 281: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1414 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 282/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1436\n",
            "Epoch 282: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1436 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 283/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1415\n",
            "Epoch 283: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1414 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 284/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1455\n",
            "Epoch 284: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 285/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1420\n",
            "Epoch 285: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 6ms/step - loss: 1.9460 - accuracy: 0.1420 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 286/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 286: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 287/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1453\n",
            "Epoch 287: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1457 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 288/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1451\n",
            "Epoch 288: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1445 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 289/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 289: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1429 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 290/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1444\n",
            "Epoch 290: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1445 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 291/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1432\n",
            "Epoch 291: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1433 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 292/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1458\n",
            "Epoch 292: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 293/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1438\n",
            "Epoch 293: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1434 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 294/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1445\n",
            "Epoch 294: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 295/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1391\n",
            "Epoch 295: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1392 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 296/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1439\n",
            "Epoch 296: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1442 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 297/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1446\n",
            "Epoch 297: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 298/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1444\n",
            "Epoch 298: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 299/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1465\n",
            "Epoch 299: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 300/1000\n",
            "257/266 [===========================>..] - ETA: 0s - loss: 1.9460 - accuracy: 0.1418\n",
            "Epoch 300: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1422 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 301/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1451\n",
            "Epoch 301: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1449 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 302/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1423\n",
            "Epoch 302: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1420 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 303/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 303: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 304/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1454\n",
            "Epoch 304: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1458 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 305/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1420\n",
            "Epoch 305: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1413 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 306/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1465\n",
            "Epoch 306: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 307/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1410\n",
            "Epoch 307: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1413 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 308/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 308: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 309/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1444\n",
            "Epoch 309: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1447 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 310/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1398\n",
            "Epoch 310: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1406 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 311/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1427\n",
            "Epoch 311: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1433 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 312/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1428\n",
            "Epoch 312: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1427 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 313/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1444\n",
            "Epoch 313: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 314/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1448\n",
            "Epoch 314: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1451 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 315/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1449\n",
            "Epoch 315: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 316/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1421\n",
            "Epoch 316: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1420 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 317/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1418\n",
            "Epoch 317: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1420 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 318/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 318: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 319/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1445\n",
            "Epoch 319: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 320/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1458\n",
            "Epoch 320: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 321/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1399\n",
            "Epoch 321: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1413 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 322/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1445\n",
            "Epoch 322: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1442 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 323/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1443\n",
            "Epoch 323: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1449 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 324/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1431\n",
            "Epoch 324: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1432 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 325/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1464\n",
            "Epoch 325: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 326/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1452\n",
            "Epoch 326: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1457 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 327/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1461\n",
            "Epoch 327: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 328/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1432\n",
            "Epoch 328: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1432 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 329/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1411\n",
            "Epoch 329: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1411 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 330/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1452\n",
            "Epoch 330: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 331/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1461\n",
            "Epoch 331: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 332/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1442\n",
            "Epoch 332: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1442 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 333/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1432\n",
            "Epoch 333: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1426 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 334/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 334: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 335/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1448\n",
            "Epoch 335: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1452 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 336/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1431\n",
            "Epoch 336: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1431 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 337/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1456\n",
            "Epoch 337: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 338/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1403\n",
            "Epoch 338: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1400 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 339/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1422\n",
            "Epoch 339: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1429 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 340/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 340: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 341/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1464\n",
            "Epoch 341: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 342/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 342: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1458 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 343/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1423\n",
            "Epoch 343: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1418 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 344/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1392\n",
            "Epoch 344: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1391 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 345/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1462\n",
            "Epoch 345: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1463 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 346/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1433\n",
            "Epoch 346: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1432 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 347/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1440\n",
            "Epoch 347: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 348/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1419\n",
            "Epoch 348: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1417 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 349/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1417\n",
            "Epoch 349: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1414 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 350/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1418\n",
            "Epoch 350: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1424 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 351/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1464\n",
            "Epoch 351: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 352/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1437\n",
            "Epoch 352: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9461 - accuracy: 0.1437 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 353/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1407\n",
            "Epoch 353: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1404 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 354/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1448\n",
            "Epoch 354: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1447 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 355/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1461\n",
            "Epoch 355: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 356/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1442\n",
            "Epoch 356: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 357/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1429\n",
            "Epoch 357: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1427 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 358/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1458\n",
            "Epoch 358: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 359/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1429\n",
            "Epoch 359: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1433 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 360/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1462\n",
            "Epoch 360: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 361/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1436\n",
            "Epoch 361: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1427 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 362/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1375\n",
            "Epoch 362: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1377 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 363/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1453\n",
            "Epoch 363: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1451 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 364/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1446\n",
            "Epoch 364: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1443 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 365/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1404\n",
            "Epoch 365: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1412 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 366/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1428\n",
            "Epoch 366: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1436 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 367/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1415\n",
            "Epoch 367: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1411 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 368/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1425\n",
            "Epoch 368: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1424 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 369/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1414\n",
            "Epoch 369: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1409 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 370/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1469\n",
            "Epoch 370: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 371/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1409\n",
            "Epoch 371: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1409 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 372/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1420\n",
            "Epoch 372: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1422 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 373/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1433\n",
            "Epoch 373: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1425 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 374/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1426\n",
            "Epoch 374: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1426 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 375/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 375: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 376/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1444\n",
            "Epoch 376: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 377/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1452\n",
            "Epoch 377: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1450 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 378/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 378: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 379/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1426\n",
            "Epoch 379: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1425 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 380/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 380: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1437 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 381/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1416\n",
            "Epoch 381: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9461 - accuracy: 0.1416 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 382/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1383\n",
            "Epoch 382: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1382 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 383/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 383: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 384/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 384: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 385/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1445\n",
            "Epoch 385: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1438 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 386/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1429\n",
            "Epoch 386: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1430 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 387/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1454\n",
            "Epoch 387: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1454 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 388/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1429\n",
            "Epoch 388: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1427 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 389/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 389: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1437 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 390/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1458\n",
            "Epoch 390: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 391/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1416\n",
            "Epoch 391: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1416 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 392/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1396\n",
            "Epoch 392: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1396 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 393/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1466\n",
            "Epoch 393: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 394/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1462\n",
            "Epoch 394: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 395/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1425\n",
            "Epoch 395: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1427 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 396/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1436\n",
            "Epoch 396: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1434 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 397/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1396\n",
            "Epoch 397: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1402 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 398/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 398: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 399/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1372\n",
            "Epoch 399: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1372 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 400/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1464\n",
            "Epoch 400: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 401/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 401: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 402/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1399\n",
            "Epoch 402: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1407 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 403/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1457\n",
            "Epoch 403: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 404/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1452\n",
            "Epoch 404: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1443 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 405/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1452\n",
            "Epoch 405: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1452 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 406/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1444\n",
            "Epoch 406: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1442 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 407/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1360\n",
            "Epoch 407: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1364 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 408/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1433\n",
            "Epoch 408: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1433 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 409/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1428\n",
            "Epoch 409: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1423 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 410/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1372\n",
            "Epoch 410: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1383 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 411/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1407\n",
            "Epoch 411: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1407 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 412/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1449\n",
            "Epoch 412: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1449 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 413/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1403\n",
            "Epoch 413: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1404 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 414/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1403\n",
            "Epoch 414: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1407 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 415/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1466\n",
            "Epoch 415: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 416/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1380\n",
            "Epoch 416: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1380 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 417/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1425\n",
            "Epoch 417: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1430 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 418/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1461\n",
            "Epoch 418: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 419/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1395\n",
            "Epoch 419: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1403 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 420/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1455\n",
            "Epoch 420: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 421/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1468\n",
            "Epoch 421: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 422/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1410\n",
            "Epoch 422: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1418 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 423/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1400\n",
            "Epoch 423: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1400 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 424/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1450\n",
            "Epoch 424: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1450 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 425/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1445\n",
            "Epoch 425: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 426/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1445\n",
            "Epoch 426: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1445 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 427/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 427: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 428/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1410\n",
            "Epoch 428: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1420 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 429/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1426\n",
            "Epoch 429: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1431 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 430/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1451\n",
            "Epoch 430: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 431/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1390\n",
            "Epoch 431: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1387 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 432/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1431\n",
            "Epoch 432: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1438 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 433/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1421\n",
            "Epoch 433: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1430 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 434/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1438\n",
            "Epoch 434: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 435/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1400\n",
            "Epoch 435: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1402 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 436/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 436: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1438 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 437/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1438\n",
            "Epoch 437: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1445 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 438/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1430\n",
            "Epoch 438: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1427 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 439/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1440\n",
            "Epoch 439: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1445 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 440/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1444\n",
            "Epoch 440: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1445 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 441/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1428\n",
            "Epoch 441: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1430 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 442/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1410\n",
            "Epoch 442: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1409 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 443/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1448\n",
            "Epoch 443: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1445 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 444/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 444: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 445/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1408\n",
            "Epoch 445: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1409 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 446/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1435\n",
            "Epoch 446: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1434 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 447/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1448\n",
            "Epoch 447: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1449 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 448/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1455\n",
            "Epoch 448: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 449/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1448\n",
            "Epoch 449: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 450/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1403\n",
            "Epoch 450: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1397 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 451/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1436\n",
            "Epoch 451: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1442 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 452/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1431\n",
            "Epoch 452: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1431 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 453/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1445\n",
            "Epoch 453: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 454/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1466\n",
            "Epoch 454: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 455/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1449\n",
            "Epoch 455: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1449 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 456/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1426\n",
            "Epoch 456: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1430 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 457/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 457: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 458/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1421\n",
            "Epoch 458: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1423 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 459/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1395\n",
            "Epoch 459: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1382 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 460/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1429\n",
            "Epoch 460: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1436 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 461/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1458\n",
            "Epoch 461: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 462/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1402\n",
            "Epoch 462: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1404 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 463/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1416\n",
            "Epoch 463: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1417 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 464/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1420\n",
            "Epoch 464: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1418 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 465/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1430\n",
            "Epoch 465: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1433 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 466/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1424\n",
            "Epoch 466: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1423 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 467/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1458\n",
            "Epoch 467: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 468/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 468: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 469/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 469: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 470/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1456\n",
            "Epoch 470: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1456 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 471/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1464\n",
            "Epoch 471: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 472/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1429\n",
            "Epoch 472: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1429 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 473/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 473: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 474/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1415\n",
            "Epoch 474: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1422 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 475/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1439\n",
            "Epoch 475: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1439 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 476/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1455\n",
            "Epoch 476: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 477/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1442\n",
            "Epoch 477: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1442 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 478/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1446\n",
            "Epoch 478: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1433 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 479/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1455\n",
            "Epoch 479: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1454 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 480/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1414\n",
            "Epoch 480: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1419 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 481/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1419\n",
            "Epoch 481: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1418 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 482/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1402\n",
            "Epoch 482: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1406 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 483/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1386\n",
            "Epoch 483: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1390 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 484/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1432\n",
            "Epoch 484: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1438 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 485/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1452\n",
            "Epoch 485: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 486/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1442\n",
            "Epoch 486: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 487/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1420\n",
            "Epoch 487: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1423 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 488/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1429\n",
            "Epoch 488: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1424 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 489/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1428\n",
            "Epoch 489: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1431 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 490/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1462\n",
            "Epoch 490: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 491/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1436\n",
            "Epoch 491: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1433 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 492/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1458\n",
            "Epoch 492: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 493/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1451\n",
            "Epoch 493: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1447 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 494/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 494: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 495/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1442\n",
            "Epoch 495: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1442 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 496/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1426\n",
            "Epoch 496: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1427 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 497/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1446\n",
            "Epoch 497: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 498/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1439\n",
            "Epoch 498: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1437 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 499/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1449\n",
            "Epoch 499: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 500/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1394\n",
            "Epoch 500: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1403 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 501/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1444\n",
            "Epoch 501: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1445 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 502/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1446\n",
            "Epoch 502: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1443 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 503/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1403\n",
            "Epoch 503: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1403 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 504/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1434\n",
            "Epoch 504: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1436 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 505/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1462\n",
            "Epoch 505: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 506/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1422\n",
            "Epoch 506: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1420 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 507/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1422\n",
            "Epoch 507: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1420 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 508/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1419\n",
            "Epoch 508: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1418 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 509/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1467\n",
            "Epoch 509: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1449 - val_loss: 1.9460 - val_accuracy: 0.1496\n",
            "Epoch 510/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1413\n",
            "Epoch 510: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1417 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 511/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 511: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1437 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 512/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1467\n",
            "Epoch 512: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 513/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1458\n",
            "Epoch 513: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 514/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1398\n",
            "Epoch 514: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1405 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 515/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1436\n",
            "Epoch 515: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1434 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 516/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 516: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 517/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1464\n",
            "Epoch 517: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 518/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1446\n",
            "Epoch 518: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 519/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1467\n",
            "Epoch 519: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 520/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1364\n",
            "Epoch 520: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1358 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 521/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1455\n",
            "Epoch 521: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1452 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 522/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1435\n",
            "Epoch 522: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1434 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 523/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1438\n",
            "Epoch 523: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1438 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 524/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1426\n",
            "Epoch 524: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1426 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 525/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1423\n",
            "Epoch 525: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9461 - accuracy: 0.1423 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 526/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1469\n",
            "Epoch 526: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 527/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1397\n",
            "Epoch 527: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1397 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 528/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1456\n",
            "Epoch 528: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 529/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1445\n",
            "Epoch 529: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1445 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 530/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1458\n",
            "Epoch 530: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 531/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1416\n",
            "Epoch 531: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1416 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 532/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1440\n",
            "Epoch 532: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1452 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 533/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1473\n",
            "Epoch 533: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 534/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1447\n",
            "Epoch 534: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1439 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 535/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1444\n",
            "Epoch 535: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1449 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 536/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1436\n",
            "Epoch 536: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1436 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 537/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1410\n",
            "Epoch 537: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1411 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 538/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1385\n",
            "Epoch 538: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1373 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 539/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1415\n",
            "Epoch 539: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1420 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 540/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1446\n",
            "Epoch 540: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 541/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1448\n",
            "Epoch 541: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 11ms/step - loss: 1.9460 - accuracy: 0.1447 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 542/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1410\n",
            "Epoch 542: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1414 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 543/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1472\n",
            "Epoch 543: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 544/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1434\n",
            "Epoch 544: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1433 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 545/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 545: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 546/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1390\n",
            "Epoch 546: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1394 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 547/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 547: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 548/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1407\n",
            "Epoch 548: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1413 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 549/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1430\n",
            "Epoch 549: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1431 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 550/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1438\n",
            "Epoch 550: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1432 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 551/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1445\n",
            "Epoch 551: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1447 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 552/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1450\n",
            "Epoch 552: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 553/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1412\n",
            "Epoch 553: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1411 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 554/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1458\n",
            "Epoch 554: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 555/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1453\n",
            "Epoch 555: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1449 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 556/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 556: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1437 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 557/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1458\n",
            "Epoch 557: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 558/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1450\n",
            "Epoch 558: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1453 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 559/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1445\n",
            "Epoch 559: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 560/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1462\n",
            "Epoch 560: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 561/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1423\n",
            "Epoch 561: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1422 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 562/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 562: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 563/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1413\n",
            "Epoch 563: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1411 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 564/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 564: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 565/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1401\n",
            "Epoch 565: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1400 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 566/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1428\n",
            "Epoch 566: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1426 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 567/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1414\n",
            "Epoch 567: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1413 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 568/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 568: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1452 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 569/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1457\n",
            "Epoch 569: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 570/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1403\n",
            "Epoch 570: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1403 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 571/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1454\n",
            "Epoch 571: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1451 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 572/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1417\n",
            "Epoch 572: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1422 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 573/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1453\n",
            "Epoch 573: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 574/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1458\n",
            "Epoch 574: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1450 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 575/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9459 - accuracy: 0.1423\n",
            "Epoch 575: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1413 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 576/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1367\n",
            "Epoch 576: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1364 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 577/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1408\n",
            "Epoch 577: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1404 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 578/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1452\n",
            "Epoch 578: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1449 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 579/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1443\n",
            "Epoch 579: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1431 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 580/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1405\n",
            "Epoch 580: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1404 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 581/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 581: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 7ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 582/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1430\n",
            "Epoch 582: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1432 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 583/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1400\n",
            "Epoch 583: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1399 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 584/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1461\n",
            "Epoch 584: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 585/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 585: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1433 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 586/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1448\n",
            "Epoch 586: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1451 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 587/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 587: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 588/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1433\n",
            "Epoch 588: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1429 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 589/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1403\n",
            "Epoch 589: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1398 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 590/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1440\n",
            "Epoch 590: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1439 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 591/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1418\n",
            "Epoch 591: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1419 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 592/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1458\n",
            "Epoch 592: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1452 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 593/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1398\n",
            "Epoch 593: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1398 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 594/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1456\n",
            "Epoch 594: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1450 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 595/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1447\n",
            "Epoch 595: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1451 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 596/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1446\n",
            "Epoch 596: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 597/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1433\n",
            "Epoch 597: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1430 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 598/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1413\n",
            "Epoch 598: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1420 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 599/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1451\n",
            "Epoch 599: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1450 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 600/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1423\n",
            "Epoch 600: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1430 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 601/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1457\n",
            "Epoch 601: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1453 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 602/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1442\n",
            "Epoch 602: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1442 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 603/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 603: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 604/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1440\n",
            "Epoch 604: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1439 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 605/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 605: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1452 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 606/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1450\n",
            "Epoch 606: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1447 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 607/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1431\n",
            "Epoch 607: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1433 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 608/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1452\n",
            "Epoch 608: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 609/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1423\n",
            "Epoch 609: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1427 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 610/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1410\n",
            "Epoch 610: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1412 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 611/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1415\n",
            "Epoch 611: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1412 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 612/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 612: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 613/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1402\n",
            "Epoch 613: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1403 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 614/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1438\n",
            "Epoch 614: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 615/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1442\n",
            "Epoch 615: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1442 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 616/1000\n",
            "258/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1406\n",
            "Epoch 616: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1414 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 617/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1446\n",
            "Epoch 617: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1447 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 618/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1404\n",
            "Epoch 618: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1404 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 619/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1411\n",
            "Epoch 619: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1409 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 620/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1428\n",
            "Epoch 620: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1423 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 621/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1462\n",
            "Epoch 621: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 11ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 622/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1444\n",
            "Epoch 622: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1439 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 623/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1389\n",
            "Epoch 623: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1389 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 624/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1449\n",
            "Epoch 624: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 625/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 625: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 626/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1454\n",
            "Epoch 626: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1453 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 627/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1393\n",
            "Epoch 627: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1393 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 628/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1420\n",
            "Epoch 628: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1422 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 629/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1411\n",
            "Epoch 629: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1411 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 630/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1423\n",
            "Epoch 630: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1419 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 631/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1384\n",
            "Epoch 631: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1385 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 632/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1452\n",
            "Epoch 632: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 633/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1416\n",
            "Epoch 633: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1416 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 634/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1452\n",
            "Epoch 634: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1449 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 635/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1416\n",
            "Epoch 635: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1416 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 636/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1444\n",
            "Epoch 636: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 637/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1425\n",
            "Epoch 637: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1420 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 638/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1439\n",
            "Epoch 638: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1437 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 639/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 639: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 640/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1422\n",
            "Epoch 640: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1422 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 641/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1446\n",
            "Epoch 641: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 642/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1430\n",
            "Epoch 642: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1425 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 643/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1463\n",
            "Epoch 643: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 644/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1456\n",
            "Epoch 644: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1447 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 645/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1433\n",
            "Epoch 645: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1434 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 646/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1430\n",
            "Epoch 646: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1426 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 647/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1447\n",
            "Epoch 647: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1447 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 648/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1440\n",
            "Epoch 648: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1434 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 649/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1418\n",
            "Epoch 649: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1418 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 650/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 650: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 651/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1440\n",
            "Epoch 651: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1438 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 652/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1397\n",
            "Epoch 652: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1400 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 653/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1444\n",
            "Epoch 653: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 654/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1421\n",
            "Epoch 654: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 9ms/step - loss: 1.9460 - accuracy: 0.1419 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 655/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1420\n",
            "Epoch 655: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1420 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 656/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1435\n",
            "Epoch 656: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1430 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 657/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1436\n",
            "Epoch 657: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1437 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 658/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1442\n",
            "Epoch 658: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 659/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 659: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 660/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1391\n",
            "Epoch 660: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1391 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 661/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1397\n",
            "Epoch 661: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1397 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 662/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 662: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 663/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1385\n",
            "Epoch 663: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1384 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 664/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1399\n",
            "Epoch 664: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1399 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 665/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1456\n",
            "Epoch 665: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 666/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 666: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 667/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1412\n",
            "Epoch 667: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1412 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 668/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1447\n",
            "Epoch 668: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1447 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 669/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1415\n",
            "Epoch 669: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1417 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 670/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1442\n",
            "Epoch 670: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 671/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1430\n",
            "Epoch 671: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1427 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 672/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1458\n",
            "Epoch 672: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1453 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 673/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 673: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 674/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1408\n",
            "Epoch 674: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1411 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 675/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1432\n",
            "Epoch 675: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 9ms/step - loss: 1.9460 - accuracy: 0.1437 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 676/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1435\n",
            "Epoch 676: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1433 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 677/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1454\n",
            "Epoch 677: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1450 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 678/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1420\n",
            "Epoch 678: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1420 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 679/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 679: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1433 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 680/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 680: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 681/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1450\n",
            "Epoch 681: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1452 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 682/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1440\n",
            "Epoch 682: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1436 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 683/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1430\n",
            "Epoch 683: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1434 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 684/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1427\n",
            "Epoch 684: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1438 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 685/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1453\n",
            "Epoch 685: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1453 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 686/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9459 - accuracy: 0.1446\n",
            "Epoch 686: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1443 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 687/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1428\n",
            "Epoch 687: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1423 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 688/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1400\n",
            "Epoch 688: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1400 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 689/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1457\n",
            "Epoch 689: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 690/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1447\n",
            "Epoch 690: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1443 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 691/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1455\n",
            "Epoch 691: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1449 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 692/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1439\n",
            "Epoch 692: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 693/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1403\n",
            "Epoch 693: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1405 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 694/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1428\n",
            "Epoch 694: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1431 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 695/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1399\n",
            "Epoch 695: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1400 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 696/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1464\n",
            "Epoch 696: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 697/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1438\n",
            "Epoch 697: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 11ms/step - loss: 1.9460 - accuracy: 0.1442 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 698/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1439\n",
            "Epoch 698: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1439 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 699/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1461\n",
            "Epoch 699: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 700/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1445\n",
            "Epoch 700: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1445 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 701/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1454\n",
            "Epoch 701: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 702/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1425\n",
            "Epoch 702: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1430 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 703/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1442\n",
            "Epoch 703: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 704/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1445\n",
            "Epoch 704: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 705/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1438\n",
            "Epoch 705: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1439 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 706/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1428\n",
            "Epoch 706: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1429 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 707/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1444\n",
            "Epoch 707: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 708/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1452\n",
            "Epoch 708: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 709/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1411\n",
            "Epoch 709: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1411 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 710/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1425\n",
            "Epoch 710: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1423 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 711/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1426\n",
            "Epoch 711: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1426 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 712/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1400\n",
            "Epoch 712: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1400 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 713/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1429\n",
            "Epoch 713: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1431 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 714/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1446\n",
            "Epoch 714: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 715/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 715: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1433 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 716/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 716: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 717/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1439\n",
            "Epoch 717: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1439 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 718/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1400\n",
            "Epoch 718: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1402 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 719/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1402\n",
            "Epoch 719: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1405 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 720/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1446\n",
            "Epoch 720: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 721/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1447\n",
            "Epoch 721: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1445 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 722/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9459 - accuracy: 0.1448\n",
            "Epoch 722: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1445 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 723/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1440\n",
            "Epoch 723: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1436 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 724/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1424\n",
            "Epoch 724: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1426 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 725/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1450\n",
            "Epoch 725: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1450 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 726/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1432\n",
            "Epoch 726: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1434 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 727/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1407\n",
            "Epoch 727: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1413 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 728/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1449\n",
            "Epoch 728: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1447 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 729/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1422\n",
            "Epoch 729: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1413 - val_loss: 1.9460 - val_accuracy: 0.1496\n",
            "Epoch 730/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1445\n",
            "Epoch 730: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1445 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 731/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1433\n",
            "Epoch 731: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1431 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 732/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1448\n",
            "Epoch 732: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 733/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1462\n",
            "Epoch 733: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 734/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 734: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 735/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1440\n",
            "Epoch 735: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1443 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 736/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1422\n",
            "Epoch 736: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1422 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 737/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1433\n",
            "Epoch 737: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1433 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 738/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1425\n",
            "Epoch 738: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1425 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 739/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1444\n",
            "Epoch 739: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1436 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 740/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1444\n",
            "Epoch 740: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 741/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 741: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1439 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 742/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1448\n",
            "Epoch 742: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 743/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1410\n",
            "Epoch 743: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1407 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 744/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1439\n",
            "Epoch 744: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1439 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 745/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1429\n",
            "Epoch 745: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1430 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 746/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1445\n",
            "Epoch 746: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1442 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 747/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1455\n",
            "Epoch 747: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 748/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1415\n",
            "Epoch 748: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1413 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 749/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1402\n",
            "Epoch 749: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1406 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 750/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1445\n",
            "Epoch 750: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1439 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 751/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 751: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 752/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1455\n",
            "Epoch 752: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1456 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 753/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1419\n",
            "Epoch 753: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1422 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 754/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1433\n",
            "Epoch 754: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1430 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 755/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1426\n",
            "Epoch 755: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1422 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 756/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1430\n",
            "Epoch 756: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1432 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 757/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1410\n",
            "Epoch 757: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1409 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 758/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1462\n",
            "Epoch 758: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 759/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1436\n",
            "Epoch 759: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1437 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 760/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1420\n",
            "Epoch 760: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1422 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 761/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1443\n",
            "Epoch 761: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 762/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1423\n",
            "Epoch 762: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1420 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 763/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1413\n",
            "Epoch 763: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1417 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 764/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1444\n",
            "Epoch 764: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1437 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 765/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 765: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 766/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1441\n",
            "Epoch 766: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1442 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 767/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1458\n",
            "Epoch 767: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 768/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1415\n",
            "Epoch 768: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1407 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 769/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1457\n",
            "Epoch 769: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 770/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1414\n",
            "Epoch 770: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1414 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 771/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1451\n",
            "Epoch 771: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1450 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 772/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1416\n",
            "Epoch 772: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 11ms/step - loss: 1.9460 - accuracy: 0.1416 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 773/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1445\n",
            "Epoch 773: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1439 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 774/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1409\n",
            "Epoch 774: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1409 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 775/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1433\n",
            "Epoch 775: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1433 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 776/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1427\n",
            "Epoch 776: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1431 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 777/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1401\n",
            "Epoch 777: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1404 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 778/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1406\n",
            "Epoch 778: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1403 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 779/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1463\n",
            "Epoch 779: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 780/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1413\n",
            "Epoch 780: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1416 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 781/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 781: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 782/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1420\n",
            "Epoch 782: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1420 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 783/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1400\n",
            "Epoch 783: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1394 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 784/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1406\n",
            "Epoch 784: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1412 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 785/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 785: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1438 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 786/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9459 - accuracy: 0.1430\n",
            "Epoch 786: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1426 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 787/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1442\n",
            "Epoch 787: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 788/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 788: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 789/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1457\n",
            "Epoch 789: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1457 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 790/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1396\n",
            "Epoch 790: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1393 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 791/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1468\n",
            "Epoch 791: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1470 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 792/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 792: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1437 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 793/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1436\n",
            "Epoch 793: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1436 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 794/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1416\n",
            "Epoch 794: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1414 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 795/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1415\n",
            "Epoch 795: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1414 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 796/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1456\n",
            "Epoch 796: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 797/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1442\n",
            "Epoch 797: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 798/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1435\n",
            "Epoch 798: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1434 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 799/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1419\n",
            "Epoch 799: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1420 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 800/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1470\n",
            "Epoch 800: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 801/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1448\n",
            "Epoch 801: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 802/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1440\n",
            "Epoch 802: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1438 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 803/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1440\n",
            "Epoch 803: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1443 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 804/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1433\n",
            "Epoch 804: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1427 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 805/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1407\n",
            "Epoch 805: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1406 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 806/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1416\n",
            "Epoch 806: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1416 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 807/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1430\n",
            "Epoch 807: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1432 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 808/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1462\n",
            "Epoch 808: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 809/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1446\n",
            "Epoch 809: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1450 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 810/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1406\n",
            "Epoch 810: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1407 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 811/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1393\n",
            "Epoch 811: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1398 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 812/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 812: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 813/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1430\n",
            "Epoch 813: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 9ms/step - loss: 1.9460 - accuracy: 0.1430 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 814/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1444\n",
            "Epoch 814: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1438 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 815/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1414\n",
            "Epoch 815: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1413 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 816/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1432\n",
            "Epoch 816: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1436 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 817/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1461\n",
            "Epoch 817: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 818/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1447\n",
            "Epoch 818: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 819/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1430\n",
            "Epoch 819: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1433 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 820/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 820: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 821/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1438\n",
            "Epoch 821: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1434 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 822/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1429\n",
            "Epoch 822: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1426 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 823/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1462\n",
            "Epoch 823: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 824/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1454\n",
            "Epoch 824: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1450 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 825/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1432\n",
            "Epoch 825: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1432 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 826/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1448\n",
            "Epoch 826: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1447 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 827/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1430\n",
            "Epoch 827: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1439 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 828/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1422\n",
            "Epoch 828: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1425 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 829/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1401\n",
            "Epoch 829: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1402 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 830/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1456\n",
            "Epoch 830: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 831/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 831: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 832/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1391\n",
            "Epoch 832: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1392 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 833/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1444\n",
            "Epoch 833: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 834/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1446\n",
            "Epoch 834: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 835/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1412\n",
            "Epoch 835: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1419 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 836/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1445\n",
            "Epoch 836: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1442 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 837/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 837: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 838/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1413\n",
            "Epoch 838: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1412 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 839/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1448\n",
            "Epoch 839: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 840/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1458\n",
            "Epoch 840: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1458 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 841/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1428\n",
            "Epoch 841: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1426 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 842/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 842: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 843/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1428\n",
            "Epoch 843: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1436 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 844/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1425\n",
            "Epoch 844: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1429 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 845/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1424\n",
            "Epoch 845: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1430 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 846/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9459 - accuracy: 0.1450\n",
            "Epoch 846: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 847/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1447\n",
            "Epoch 847: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 848/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1452\n",
            "Epoch 848: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 849/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1410\n",
            "Epoch 849: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1410 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 850/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 850: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1436 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 851/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1465\n",
            "Epoch 851: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 852/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 852: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1433 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 853/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1435\n",
            "Epoch 853: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9461 - accuracy: 0.1439 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 854/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1387\n",
            "Epoch 854: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1386 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 855/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1439\n",
            "Epoch 855: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1438 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 856/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 856: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 857/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9459 - accuracy: 0.1417\n",
            "Epoch 857: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1414 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 858/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1454\n",
            "Epoch 858: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1454 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 859/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1414\n",
            "Epoch 859: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1412 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 860/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1425\n",
            "Epoch 860: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1427 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 861/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1436\n",
            "Epoch 861: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1434 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 862/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1407\n",
            "Epoch 862: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1407 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 863/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1448\n",
            "Epoch 863: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1445 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 864/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1458\n",
            "Epoch 864: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 865/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1451\n",
            "Epoch 865: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1445 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 866/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 866: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1453 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 867/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1432\n",
            "Epoch 867: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1432 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 868/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1440\n",
            "Epoch 868: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1442 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 869/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1369\n",
            "Epoch 869: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1369 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 870/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1456\n",
            "Epoch 870: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 871/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1355\n",
            "Epoch 871: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1359 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 872/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1412\n",
            "Epoch 872: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1412 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 873/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1463\n",
            "Epoch 873: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 874/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1446\n",
            "Epoch 874: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 875/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1411\n",
            "Epoch 875: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1418 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 876/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9459 - accuracy: 0.1444\n",
            "Epoch 876: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1443 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 877/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1430\n",
            "Epoch 877: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1431 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 878/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1418\n",
            "Epoch 878: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1419 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 879/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1421\n",
            "Epoch 879: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1425 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 880/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1460\n",
            "Epoch 880: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 881/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1409\n",
            "Epoch 881: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1410 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 882/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1440\n",
            "Epoch 882: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 883/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1440\n",
            "Epoch 883: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1439 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 884/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1456\n",
            "Epoch 884: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1452 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 885/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1423\n",
            "Epoch 885: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1432 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 886/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1463\n",
            "Epoch 886: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 887/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1439\n",
            "Epoch 887: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 888/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1450\n",
            "Epoch 888: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1453 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 889/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1406\n",
            "Epoch 889: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1406 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 890/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1444\n",
            "Epoch 890: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1442 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 891/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1404\n",
            "Epoch 891: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1411 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 892/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1461\n",
            "Epoch 892: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 893/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1353\n",
            "Epoch 893: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.1356 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 894/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1439\n",
            "Epoch 894: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1439 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 895/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1453\n",
            "Epoch 895: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 896/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1445\n",
            "Epoch 896: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1445 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 897/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1458\n",
            "Epoch 897: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 898/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1400\n",
            "Epoch 898: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 9ms/step - loss: 1.9460 - accuracy: 0.1403 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 899/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1424\n",
            "Epoch 899: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1425 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 900/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 900: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1434 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 901/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1440\n",
            "Epoch 901: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1439 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 902/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1421\n",
            "Epoch 902: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1418 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 903/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1447\n",
            "Epoch 903: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1439 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 904/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1430\n",
            "Epoch 904: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1430 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 905/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1453\n",
            "Epoch 905: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1443 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 906/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1412\n",
            "Epoch 906: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1410 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 907/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1441\n",
            "Epoch 907: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1438 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 908/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1422\n",
            "Epoch 908: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1422 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 909/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1420\n",
            "Epoch 909: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1420 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 910/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9461 - accuracy: 0.1434\n",
            "Epoch 910: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9461 - accuracy: 0.1436 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 911/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 911: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 912/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1406\n",
            "Epoch 912: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1405 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 913/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 913: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 914/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1449\n",
            "Epoch 914: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1449 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 915/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1418\n",
            "Epoch 915: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1413 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 916/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1454\n",
            "Epoch 916: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 917/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1407\n",
            "Epoch 917: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1410 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 918/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1433\n",
            "Epoch 918: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1431 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 919/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9459 - accuracy: 0.1430\n",
            "Epoch 919: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 11ms/step - loss: 1.9460 - accuracy: 0.1419 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 920/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1436\n",
            "Epoch 920: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1433 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 921/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1440\n",
            "Epoch 921: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 922/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1399\n",
            "Epoch 922: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1398 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 923/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1463\n",
            "Epoch 923: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 924/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1448\n",
            "Epoch 924: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 925/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 925: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1434 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 926/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1459\n",
            "Epoch 926: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 927/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1428\n",
            "Epoch 927: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1430 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 928/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1440\n",
            "Epoch 928: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 9ms/step - loss: 1.9460 - accuracy: 0.1438 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 929/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1422\n",
            "Epoch 929: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1422 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 930/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1448\n",
            "Epoch 930: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 931/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1409\n",
            "Epoch 931: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1409 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 932/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1446\n",
            "Epoch 932: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 933/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1448\n",
            "Epoch 933: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 9ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 934/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1425\n",
            "Epoch 934: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1425 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 935/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1451\n",
            "Epoch 935: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1447 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 936/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1368\n",
            "Epoch 936: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1370 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 937/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1464\n",
            "Epoch 937: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 938/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1441\n",
            "Epoch 938: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 939/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1458\n",
            "Epoch 939: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1453 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 940/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1432\n",
            "Epoch 940: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1431 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 941/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1449\n",
            "Epoch 941: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 942/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1463\n",
            "Epoch 942: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 943/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 943: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1437 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 944/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1404\n",
            "Epoch 944: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1410 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 945/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 945: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1449 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 946/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1440\n",
            "Epoch 946: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1436 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 947/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1405\n",
            "Epoch 947: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1405 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 948/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1463\n",
            "Epoch 948: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 949/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1461\n",
            "Epoch 949: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 950/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1435\n",
            "Epoch 950: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1431 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 951/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1398\n",
            "Epoch 951: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1399 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 952/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1444\n",
            "Epoch 952: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1439 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 953/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1439\n",
            "Epoch 953: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1438 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 954/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1452\n",
            "Epoch 954: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 9ms/step - loss: 1.9460 - accuracy: 0.1452 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 955/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1375\n",
            "Epoch 955: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 9ms/step - loss: 1.9460 - accuracy: 0.1374 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 956/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1428\n",
            "Epoch 956: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1427 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 957/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1431\n",
            "Epoch 957: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1429 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 958/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1415\n",
            "Epoch 958: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1417 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 959/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1438\n",
            "Epoch 959: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1433 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 960/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1442\n",
            "Epoch 960: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1438 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 961/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1417\n",
            "Epoch 961: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1417 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 962/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1429\n",
            "Epoch 962: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 9ms/step - loss: 1.9460 - accuracy: 0.1423 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 963/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1426\n",
            "Epoch 963: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1426 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 964/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 964: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1437 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 965/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9459 - accuracy: 0.1447\n",
            "Epoch 965: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 9ms/step - loss: 1.9460 - accuracy: 0.1446 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 966/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1445\n",
            "Epoch 966: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 967/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1426\n",
            "Epoch 967: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1427 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 968/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1415\n",
            "Epoch 968: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1414 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 969/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1435\n",
            "Epoch 969: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1433 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 970/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1439\n",
            "Epoch 970: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1447 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 971/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1458\n",
            "Epoch 971: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1450 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 972/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1419\n",
            "Epoch 972: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1417 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 973/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1394\n",
            "Epoch 973: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1398 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 974/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1433\n",
            "Epoch 974: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1432 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 975/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1412\n",
            "Epoch 975: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1411 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 976/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1465\n",
            "Epoch 976: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 9ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 977/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1442\n",
            "Epoch 977: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 9ms/step - loss: 1.9460 - accuracy: 0.1444 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 978/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1455\n",
            "Epoch 978: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1451 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 979/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1413\n",
            "Epoch 979: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1412 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 980/1000\n",
            "260/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1442\n",
            "Epoch 980: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1445 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 981/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1414\n",
            "Epoch 981: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1413 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 982/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1452\n",
            "Epoch 982: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1452 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 983/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1440\n",
            "Epoch 983: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1438 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 984/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1439\n",
            "Epoch 984: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1436 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 985/1000\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.9460 - accuracy: 0.1447\n",
            "Epoch 985: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 9ms/step - loss: 1.9460 - accuracy: 0.1447 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 986/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1427\n",
            "Epoch 986: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1422 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 987/1000\n",
            "262/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1443\n",
            "Epoch 987: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 988/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1458\n",
            "Epoch 988: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1459 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 989/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1376\n",
            "Epoch 989: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1376 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 990/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1431\n",
            "Epoch 990: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1432 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 991/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1445\n",
            "Epoch 991: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1447 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 992/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1399\n",
            "Epoch 992: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1400 - val_loss: 1.9459 - val_accuracy: 0.1496\n",
            "Epoch 993/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1384\n",
            "Epoch 993: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1379 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 994/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1449\n",
            "Epoch 994: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1450 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 995/1000\n",
            "261/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1450\n",
            "Epoch 995: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1439 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 996/1000\n",
            "265/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1440\n",
            "Epoch 996: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 9ms/step - loss: 1.9460 - accuracy: 0.1440 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 997/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1437\n",
            "Epoch 997: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1438 - val_loss: 1.9459 - val_accuracy: 0.1397\n",
            "Epoch 998/1000\n",
            "263/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1434\n",
            "Epoch 998: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1439 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 999/1000\n",
            "264/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1423\n",
            "Epoch 999: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 3s 10ms/step - loss: 1.9460 - accuracy: 0.1422 - val_loss: 1.9460 - val_accuracy: 0.1397\n",
            "Epoch 1000/1000\n",
            "259/266 [============================>.] - ETA: 0s - loss: 1.9460 - accuracy: 0.1451\n",
            "Epoch 1000: saving model to bestmodel.h5\n",
            "266/266 [==============================] - 2s 9ms/step - loss: 1.9460 - accuracy: 0.1447 - val_loss: 1.9460 - val_accuracy: 0.1397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model"
      ],
      "metadata": {
        "id": "I_aljuQYX011"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bestmodel = load_model('bestmodel.h5')"
      ],
      "metadata": {
        "id": "nzXS-5Y9X011"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bestmodel.summary()"
      ],
      "metadata": {
        "id": "r124aeGAX012",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e731bd72-6cd3-44f0-bde7-c708d4e9ad06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 256)               14336     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 256)               512       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 180,043\n",
            "Trainable params: 180,043\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bestmodel.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "JXeCshFbX012",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0acb5b62-d141-48fa-9e50-dda8e46ecd05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "119/119 [==============================] - 0s 2ms/step - loss: 1.9466 - accuracy: 0.1384\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.9465960264205933, 0.13835978507995605]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Avoidable bias or variance\n",
        "\n",
        "# Avoidable Bias is more.\n"
      ],
      "metadata": {
        "id": "VvNz6MqDX014"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}